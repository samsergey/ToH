<i>Продолжаю знакомить читателей Хабра с главами из своей книжки «Теория счастья» с подзаголовком «Математические основы законов подлости». Это ещё не изданная научно-популярная книжка, очень неформально рассказывающая о том, как математика позволяет с новой степенью осознанности взглянуть на мир и жизнь людей. Она для тех кому интересна наука и для тех, кому интересна жизнь. А поскольку жизнь наша сложна и, по большому счёту, непредсказуема, упор в книжке делается, в основном, на теорию вероятностей и математическую статистику. Здесь не доказываются теоремы и не даются основы науки, это ни в коем случае не учебник, а то, что называется recreational science. Но именно такой почти игровой подход позволяет развить интуицию, скрасить яркими примерами лекции для студентов и, наконец, объяснить нематематикам и нашим детям, что же такого интересного мы нашли в своей сухой науке.</i>

Опубликованные главы:

&emsp;•&ensp; <a href="https://habr.com/post/416941/">Введение в мерфологию</a>
&emsp;•&ensp; <a href="https://habr.com/post/416551/">Закон арбузной корки и нормальность ненормальности</a>
&emsp;•&ensp; <a href="https://habr.com/post/416907/">Закон зебры и чужой очереди</a>
&emsp;•&ensp; <a href="https://habr.com/post/421351/"> Проклятие режиссёра и проклятые принтеры</a>
&emsp;•&ensp; <a href="https://habr.com/post/424071/"> Термодинамика классового неравенства</a>

<abbr title="Algorithmic and Skeptical Digital Art by Giuseppe Randazzo.|CutPaste Studio"><img src="https://i.pinimg.com/750x/15/41/14/1541149beda9bac341b8f7b0de523917.jpg" alt="Algorithmic and Skeptical Digital Art by Giuseppe Randazzo.|CutPaste Studio" width="70%" align='center'/></abbr>

В этой главе мы порассуждаем о полёте бутерброда с маслом, о случайности выпадения орла или решки и, вообще, о природе случайности. А по пути заглянем в такие разделы математики, как теория мер, теория динамического хаоса и анализ размерностей.

<cut />

Разговор о законах подлости, как источнике житейских неурядиц, часто начинается со знаменитого <b>закона бутерброда</b>. Он просто формулируется, легко проверяется и широко известен:
<blockquote>Бутерброд всегда падает маслом вниз.</blockquote>
Понятно, что слово "всегда" здесь -- это преувеличение. Легко представить себе условия, в которых бутерброд упадет, оставив намазанную маслом сторону в сохранности. Что же люди понимают, под этим законом? Скорее всего, что бутерброд падает маслом вниз достаточно часто, чтобы это было заметно. Но чаще ли происходит неблагоприятный исход падения, чем благоприятный? Бутерброды разные, падают при различных обстоятельствах, с разной высоты... Параметров столько, что говорить о закономерностях в такой задаче, наверное, нет смысла. Всяко бывает. Бывает, что падает маслом вниз, тогда становится обидно, мы вспоминаем про закон и запоминаем его. А если бутерброд падает неинтересно -- маслом кверху, или если он оказался без масла вовсе, так и говорить не о чем -- понятно же, что закон-то шуточный! В конце концов, бутерброд подобен монетке, которую математики используют для получения случайных величин с двумя возможными значениями "орёл" и "решка". Если монетка "честная", то ей абсолютно неважно какой стороной падать, и мы говорим, что вероятность падения орла и решки одинаковы и равны $inline$1/2$inline$. По идее, с бутербродами дела должны обстоять также. 

Однако, тут есть тонкости. Монетку в теоретиковероятностных экспериментах подбрасывают каким-то особым магическим образом, так чтобы выбор начального положения, начальной скорости и скорости закручивания монетки при подбрасывании никак не влиял на вероятность конкретного исхода. Но очевидно же что это невозможно! Монетка представляет собой механическую систему и подчиняется законам механики, а они не содержат в себе случайных величин. Будущее в законах движения такого простого тела как монетка однозначно определяется прошлым состоянием этого тела. Если монетку будет подбрасывать робот, или демон Лапласа -- мифическое существо, обладающее полной информацией о координатах и скоростях любой механической системы, то при неизменных начальных данных, он будет получать идентичные результаты. Мы, конечно, не роботы и не демоны, но неужели люди подбрасывают монетки настолько неряшливо и непредсказуемо, что законы механики могут приводить к случайностям?

Это серьёзный вопрос: откуда берётся случайность в мире, описываемом законами механики? Откуда вообще, берётся случайность? В чём разница между истинно хаотическими или стохастическими системами, принципиально непредсказуемыми, и системами, в которых просто трудно угадать поведение, но его, в принципе, можно рассчитать?

<h3>Случайности не случайны?</h3>
Эта задача рассматривалась в 1986 году Джозефом Келлером. Мы приведём простое объяснение возникновению неопределённости в процессе подбрасывания монетки, основанное на рассуждениях из статьи Келлера. То какой стороной упадёт монетка, зависит только от времени её полёта $inline$t$inline$ и от угловой скорости $inline$\omega$inline$. Если измерять угловую скорость в оборотах за единицу времени, то число оборотов, совершаемое монеткой, выражается предельно просто $inline$n = t \omega$inline$. Эта зависимость задаёт линии равного числа оборотов в координатах $inline$(t,\omega)$inline$, а они, в свою очередь, ограничивают области, соответствующие чётному и нечётному числу оборотов.

<img src="https://habrastorage.org/webt/2u/am/t-/2uamt-kpskdnr1qg0nkmsyywjyw.png" width="70%" align="center"/><i><font color="#444">Диаграмма, показывающая чётность количества оборотов, совершаемых монеткой в полёте.</font></i>

На такой диаграмме можно показать каким будет результат подбрасывания монетки, закрученной на известное число оборотов в секунду, и пойманной через полсекунды после подбрасывания. Если попадаем в белую полоску, то выпадет та же сторона, что была сверху при подбрасывании, если в оранжевую -- обратная. Линии равного числа оборотов представляют собой гиперболы и видно, что по мере увеличения числа оборотов, чередование областей становится всё более и более частым, а сами области становятся тоньше. Человеческая рука несовершенна и очень небольшой разброс начальных значений перекрывает сразу много областей, делая исход непредсказуемым. В диапазоне действия руки (прямоугольник  на диаграмме) достаточно смещения на $inline$5\%$inline$ чтобы перескочить с белой полоски на оранжевую. Остаётся вопрос: а равны ли площади областей прямого и обратного положения монетки? От этого зависит насколько "честным" будет процесс подбрасывания.

Вообще говоря, площадь каждой полоски на нашей диаграмме бесконечна (если рассматривать всю четверть координатной плоскости). Однако, можно аккуратно показать, что это не мешает площадям заштрихованных и белых областей быть одинаковыми. Площадь -- является <i>мерой</i> плоской фигуры. Это точный математический термин, обозначающий некую величину, соответствующую измеримому множеству. Одно из главных свойств меры -- <i>аддитивность</i>, это значит, что при разбиении множества на непересекающиеся части, дополняющие друг друга до целого, сумма мер частей равна мере всего множества. Примерами мер являются количества в перечислимых множествах (количество яблок в мешке, количество рациональных чисел на отрезке), а также длины, площади, объёмы фигур. Понятие <i>вероятность</i> тоже определяется, как мера на особом множестве, называемом <i>вероятностным пространством</i>, оно включает в себя как элементарные события, так и их комбинации (объединения, пересечения и исключения).

В явном виде уравнения для наших кривых имеют вид $inline$\omega = n/t$inline$. Если  площадь под кривой $inline$\omega = 1/t$inline$ равна $inline$S$inline$, то благодаря свойству аддитивности, площадь под кривой $inline$\omega = n/t$inline$ будет равна $inline$S_n = n S$inline$. В свою очередь, для отдельных полосок получаем: $inline$ S_{n} - S_{n-1} = n S - (n-1)S = S$inline$. Выходит, разница площадей не зависит от "номера" гиперболы. Это не что-то особенное, относящееся к гиперболам, тот же вывод можно сделать для любой кривой вида $inline$y = n f(x)$inline$, лишь бы функция $inline$f$inline$ была измерима. Понятие меры позволяет взаимооднозначно связать площадь области и вероятность попадания точки в эту область. А раз так, то для всей области определения, попадания в белую часть диаграммы или в заштрихованную равновероятны, как и ожидается для "честной" монетки. 

Рассуждения, которые мы сейчас привели, кажутся достаточно простыми, но они дают весьма общий результат, применимый к любым аддитивным величинам. Абстрактное понятие меры позволило нам  сравнивать между собой бесконечные величины, оставаясь в рамках логики и здравого смысла, и с этим понятием мы ещё встретимся. В математике существует целый раздел, который называется <i>теорий мер</i>. Эта теория родилась на рубеже IXX -- XX веков и открыла математикам широкие возможности для анализа очень сложно устроенных объектов: канторовых и фрактальных множеств. Она легла в основу функционального анализа и современной теории вероятностей. 

Абстракции это хорошо, но можно возразить, что в реальности мы подбрасываем монетки не со всеми возможными параметрами. Как показали эксперименты со скоростной камерой, угловые скорости попадают в диапазон от $inline$20$inline$ до $inline$40$inline$ оборотов в секунду, а длительность полёта -- от половины до одной секунды. Эта область выделена прямоугольником на диаграмме. В ней суммарная площадь белых полосок чуть больше чем оранжевых, и можно сделать вывод, что вероятность выпадения той же стороны, что была при подбрасывании, составит $inline$50.6\%$inline$.

В 2007 году группа Перси Диакониса с соавторами из Стэнфорда опубликовала <a href="https://statweb.stanford.edu/~susan/papers/headswithJ.pdf">статью</a>, в которой даётся развёрнутый анализ  процесса подбрасывания монетки. Детальное описание механики летящего и вращающегося диска, который, не просто вращается вокруг какой-то оси, а ещё и прецессирует -- ось вращения сама вращается в полёте, показывает, что при ручном подбрасывании из позиции орел сверху, вероятность выпадения орла на одну сотую больше половины. 

Много это или мало? Сколько нужно провести экспериментов, чтобы заметить такую разницу? По мере накопления экспериментальных данных, стандартная ошибка среднего, отражающая погрешность, с которой может быть вычислена средняя величина, уменьшается пропорционально квадратному корню из числа испытаний. $$display$$\sigma_{\mu} = \frac{\sigma}{\sqrt{n}},$$display$$ здесь $inline$\sigma$inline$ -- стандартное отклонение для исследуемого распределения. В нашем случае, для распределения Бернулли с вероятностью $inline$0.51$inline$, которое равно $inline$\sqrt{0.51\times0,49}\approx0.5$inline$. Чтобы уверенно выделить отклонение среднего в одну сотую, это отклонение должно превышать $inline$3$inline$ стандартных отклонения. Таким образом, мы можем оценить число испытаний: $$display$$n =
\left(\frac{\sigma}{\sigma_{\mu}}\right)^2 = \left(\frac{3\times0.5}{0.01}\right)^2 \approx 22500$$display$$ Столько раз нужно подбросить монетку, чтобы заметить механистическую предопределённость результата. Чтобы было понятнее, что имеется ввиду, приведу пример двухсот испытаний идеальной и слегка неидеальной "монеток", проводимых с целью вычислить вероятность выпадения, скажем, орла. Каждое испытание состоит в $inline$40000$inline$ "подбрасываниях". Слова "монетка" и "подбрасывание" взяты в кавычки, оттого, что на самом деле использовалась не физическая монетка, а генератор случайных чисел, подчиняющихся распределению Бернулли.

<img src="https://habrastorage.org/webt/pq/d2/hp/pqd2hpbqdysnxmwcw19gcili-kc.png" width="80%" align="center"/><i><font color="#444">Эксперименты с подбрасыванием идеальной и слегка неидеальной монетки с целью зафиксировать неидеальность.</font></i>

Видно, что только после $inline$20000$inline$ испытаний "облака" наблюдаемых значений среднего начинают отчётливо разделяться. Что же, для бытового использования можно считать, что монетка -- неплохой генератор случайного выбора из двух равновероятных вариантов. 

<img src="https://habrastorage.org/webt/9i/tt/42/9itt42myvc71zegikqmk7mro9jy.jpeg" width="40%" align="left"/>В сувенирных лавках можно найти магнитные маятники для "выбора желаний". Они тоже являются механическими генераторами случайности и их иногда ошибочно называют "хаотическими маятниками". Начав движение с каких-то начальных позиции и скорости, маятник совершает ряд "непредсказуемых" колебаний и, наконец, останавливается в одном из секторов. Однако колебания и здесь не являются непредсказуемыми, просто они очень чувствительны к начальным условиям. Для каждого сектора, в котором может остановиться маятник, существует <i>область притяжения</i> в пространстве координат-скорости. Это множество таких начальных условий при которых маятник обязательно притянется к определённой точке в указанном секторе. Точка в которой заканчивается движение маятника называется <i>аттрактором</i> -- притягивающей точкой. В случае маятника с картинки пространство координат и скоростей четырёхмерно, и так просто области притяжения не показать. Но если ограничиться лишь двумя секторами и свести задачу к одномерной (такой маятник называется осциллятором Дюффинга), то пространство начальных значений превратится в плоскость, так что области притяжения можно будет увидеть. Они выглядят как замысловатый символ "Инь-Янь", быстро превращающийся в узкие полоски, разделяющие области притяжения. 

<img src="https://habrastorage.org/webt/yq/lc/dy/yqlcdyo5rpkf-ewr7nbo4cxengo.png" width="70%" align="center"/><i><font color="#444">Области притяжения аттракторов для одномерного маятника желаний -- осциллятора Дюффинга.</font></i>

Как и в случае с монетой, немного смещая начальные условия мы попадаем от одного аттрактора к другому. Так же действует и игральная кость и рулетка, но они не являются сами по себе генераторами случайности. Это не истинно хаотические системы и их поведение можно точно рассчитать. 

А что же такое настоящая случайность? Хороший пример истинно стохастической системы -- появление автомобилей на дороге. Люди не договариваются, не согласовывают свои планы, каждый элемент ансамбля за пределами дороги действует независимо. И хотя в поведении людей есть определённые закономерности -- часы пик утром и вечером, пустые дороги ночью и т.д., мы не обладаем и никогда не будем обладать достаточной информацией о каждом участнике движения, чтобы предсказать появление любого из них. Также стохастическими являются механика элементарных частиц на квантовом уровне, распад нестабильных атомов, изменения в генетическом коде, по всей видимости, землетрясения и котировки ценных бумаг на бирже. Единственное, что остаётся исследователю, это рассматривать их, как случайные величины и описывать в терминах теории вероятности.

Но есть и другой источник случайностей -- <i>динамический хаос</i>. Хаотические системы отличаются от стохастических тем, что описываются точными уравнениями и параметрами, не содержащими случайностей. Однако их поведение не просто сложно, а хаотично и истинно непредсказуемо. Если мы начнём колебать маятник желаний, очень аккуратно, с точно контролируемой частотой и амплитудой, то мы обнаружим что его плавные движения невозможно просчитать надолго. Никакими алгоритмами на сколь угодно точных вычислительных машинах нам не удастся рассчитать точное поведение маятника на произвольно долгое будущее. Он не остановится на каком-либо секторе, а будет совершать плавные движения, но никогда не вернётся в одну и ту же точку в пространстве координат-скорости дважды. Ещё один пример предельно простой хаотической системы -- идеальный шарик, подпрыгивающий в поле тяжести на идеальном столике с пружинкой. Сравнительно простые уравнения Лоренца показали, что мы никогда не сможем предсказывать погоду больше чем на пару-тройку недель -- это тоже хаотическая система. 

Теории динамического хаоса, удалось объяснить природу такой непредсказуемости. Простой одномерный маятник желаний, который мы рассматривали, имел две устойчивые стационарные точки -- два аттрактора, и одну неустойчивую, от  которой система старается уйти, она показана белым кружком. В хаотическом режиме вместо набора аттракторов в системе появляется бесконечное множество неустойчивых стационарных траекторий. Это множество бесконечно, но имеет <i>нулевую меру</i>, и представляет собой очень сложно устроенную несвязную структуру. Попав на одну таких траекторий, в принципе невозможно ей следовать, используя какие-либо конечные алгоритмы. Но самое удивительное, оказалось, что это бесконечное множество неустойчивых траекторий само по себе является притягивающим! <img src="https://habrastorage.org/webt/z-/m3/do/z-m3do2rhl7w0uzt4idcnepnpxa.png" width="50%" align="right"/> Хаотическая система непрерывно перескакивает от окрестности одной неустойчивой траектории к другой, всё время оставаясь в пределах это странного аттрактора. Так эти множества и называются: <i>странные аттракторы</i>. Вот как завораживающе красиво выглядит сечение плоскостью странного аттрактора для маятника желаний, подверженного гармоническим колебаниям. Этот объект для одномерного маятника можно описать в трёхмерном пространстве (координата, скорость, фаза вынужденного колебания). Если рассечь аттрактор в этом пространстве плоскостью то можно увидеть его структуру, это называется <i>сечением Пуанкаре</i>. Каждая точка здесь -- это след траектории, а цвет точек отражает относительную скорость с которой траектории разбегаются друг от друга.

Гладкость хаотической траектории позволяет всё же немного заглядывать в будущее. Это объясняет одно досадное наблюдение: с одной стороны, синоптики, порой, не могут уверенно предсказать погоду на неделю, но с другой, если вы скажете, что завтра будет такая же погода, как и сегодня, то не ошибётесь примерно в трёх случаях из четырёх. Вообще же, анекдоты о синоптиках несправедливы и нужно отдать должное человеческой мысли и упорству, которые позволили предсказывать погоду на современном уровне! 

Динамический хаос очень сложен и красив как теория, он порождает изумительные по элегантности образы, но он может быть ещё и полезен. Например, алгоритмы, с помощью которых генерируются случайные числа в компьютерах тоже детерминированы. Для примеров в этой книге, я пользовался генератором псевдослучайных чисел, который не запускал реальный стохастический процесс (альфа-распад, или подсчёт машин на дороге), а вычислял следующее "случайное" число на базе предыдущих, полученных им ранее.

<h3>От монеток к бабочкам и самой судьбе</h3>

Наблюдения за тем, как малые отклонения вырастают в глобальные изменения системы, приводят к мысли об "эффекте бабочки". Напомню, что под этим эффектом подразумевается цепочка далеко идущих драматичных последствий от некоторого незначительного, на первый взгляд, события. Раздавленная исследователями прошлого бабочка в рассказе Рея Бредбери "И грянул гром" привела к кардинальной перестройке будущего. А одну из своих лекций Эдвард Лоренц, создатель теории динамического хаоса, озаглавил так: "Может ли взмах крыла бабочки в Бразилии вызвать торнадо в Техасе?"

На этот эффект мы неявно ссылаемся, сетуя: "Не поверни я за угол, всё было бы по-другому!", "Не сел бы он в этот поезд, с ним не случилось бы катастрофы!" или "Из-за такой мелочи разругались и разошлись!!" Но мы видим, что в мире сосуществуют истинно стохастический квантовый мир и сверхточные атомные часы, устойчивые гамильтоновы системы в мире звёзд и галактик и хаос колец Сатурна и пояса Койпера, тепловое движения молекул и удивительная точность работы биологических систем или механизмов автомобиля. Нет, взмах крыла бабочки не порождает ураганов, а бесследно исчезает, порождая цепочку вихрей, передающих энергию и информацию всё более и более мелким вихрям, покуда и та и другая не исчезнут в хаосе флуктуаций.  Надо чётко понимать, что малые отклонения приводят к кардинальной перестройке системы лишь, если она неустойчива или если система находится на пороге <i>бифуркации</i> или <i>катастрофы</i> -- так на языке математики называются глобальные перестройки в поведении системы при малых изменениях параметров. А бифуркации всегда образуют множества нулевой меры в пространстве параметров -- это точки или границы. Малые возмущения не приводят к катастрофам <i>почти всюду</i>, (это точный термин означающий "везде, кроме множества нулевой меры"), а неустойчивые состояния в природе наблюдаются редко, не проходя "проверку временем".  

Если пара распалась "из-за ерунды", ей суждено было распасться в любом случае, она была неустойчивой. Устойчивые пары проходят сквозь войны и голод, а потом, бывает и, распадаются, но не из-за мелочей, а в результате глубоких перемен, могущих произойти с личностью в течение жизни. В цепочке событий, приведших к катастрофе поезда нелегко однозначно выделить ключевое событие (конкретную ошибку или роковую случайность) и, скорее всего, ключевым будет не событие, а систематическое нарушение правил, приводящее систему к неустойчивому состоянию.  Если в системе множество параметров, и ряд из них случаен, а наша жизнь устроена именно так, то информация в такой системе имеет свойство теряться и уже никак не удастся восстановить в какой именно момент в нашей жизни "всё пошло не так". Не терзайте себя сожалениями о случившемся, а присмотритесь к происходящему с вами сейчас, чтобы не пропустить настоящей точки бифуркации.

В этой связи можно вспомнить один из законов мерфологии, названный неким Дрейзеном <b>законом восстановления</b>:
<blockquote>Время улучшения ситуации обратно пропорционально времени ее ухудшения.
</blockquote>В качестве примера приводится следующее наблюдение: <i><font color="#800">На склеивание вазы уходит больше времени, чем на то, чтобы ее разбить.</font></i> Этот закон удивительно точно описывает соотношение между характерными временами для процесса релаксации для устойчивой системы, которую можно описать убывающим экспоненциальным законом и времени развития катастрофического процесса в неустойчивой системе, в линейном приближении -- экспоненциальным ростом малого возмущения. Пример с вазой, правда относится к другому процессу -- к самоорганизации, этот процесс соответствует логистическому закону и близок по характеру к релаксации. 
