Не так давно на Хабре появилась отличная и вдохновляющая статья про компиляторы и стековые машины. В ней автор проходит путь от простой реализации исполнителя байт-кода ко всё более и более эффективным версиям. Мне захотелось показать на примере разработки стековой машины, как это можно сделать Haskell-way.

На примере интерпретации языка для стековой машины мы увидим, как математическая концепция полугрупп и моноидов помогает разрабатывать и расширять архитектуру программы, как можно использовать алгебру моноидов и каким образом можно строить программы в форме набора гомоморфизмов между алгебраическими структурами. В качестве рабочих примеров мы сначала построим интерпретатор, неотделимый от кода в виде EDSL, а потом научим его разным штукам: вести запись произвольной отладочной информации, отделять код программы от самой программы, проводить простой статический анализ и вычислять с различными эффектами.  

Статья рассчитана на тех, кто владеет языком Haskell на среднем уровне и выше, на тех, кто его уже использует в работе или исследованиях и на всех любопытных, заглянувших поглядеть чего это функциональщики ещё понаворотили. Ну, и для тех, конечно, кого не испугал предыдущий абзац.

<cut />

Задачи трансляции и интерпретации дарят множество интересных и полезных примеров для демонстрации самых разных аспектов программирования. Они позволяют переходить на разные ступени сложности и абстракции, оставаясь при этом вполне практичными. В этой статье мы сосредоточимся на демонстрации возможностей двух важных математических структур -- *полугруппы* и *моноида*. Они не так часто обсуждаются, как монады или линзы, ими не пугают маленьких детей, эти структуры существенно проще для понимания, но при всём том, они лежат в основе функционального программирования. Виртуозное владение моноидальными типами, которое демонстрируют профессионалы, вызывает восхищение простотой и изяществом решений.

Поиск слова "моноид" по статьям на Хабре выдаёт не более четырёх десятков статей (про те же монады, например, их три сотни). Все они концептуально начинают с чего-то вроде: *моноид это такое множество...* а потом со вполне понятным восторгом перечисляют что является моноидом от строк до пальчиковых деревьев, от парсеров регулярных выражений до бог знает ещё чего! Но на практике мы мыслим в обратном порядке: у нас есть объект, который необходимо моделировать, мы анализируем его свойства и обнаружив, что он обладает признаками той или иной абстрактной структуры, решаем: нужны ли нам следствия из этого обстоятельства и как нам это использовать. Мы пройдём именно этим путём. А заодно добавим в коллекцию полезных моноидов ещё парочку интересных примеров.

### Языки и программы стековых машин

Стековые машины при изучении функционального программирования, обычно появляются в тот момент, когда подходят к концепции свёртки. При этом приводится крайне лаконичная реализация исполнителя простейшего стекового калькулятора, например, такая:

<spoiler title="Простейший стековый калькулятор">
```haskell
calc :: String -> [Int]
calc = interpretor . lexer
  where
    lexer = words
    interpretor = foldl (flip interprete) []
    interprete c = case c of
      "add" -> binary $ \(x:y:s) -> x + y:s
      "mul" -> binary $ \(x:y:s) -> x * y:s
      "sub" -> binary $ \(x:y:s) -> y - x:s
      "div" -> binary $ \(x:y:s) -> y `div` x:s
      "pop" -> unary  $ \(x:s) -> s
      "dup" -> unary  $ \(x:s) -> x:x:s
      x -> case readMaybe x of
        Just n -> \s -> n:s
        Nothing -> error $ "Error: unknown command " ++ c
      where
        unary f s = case s of
          x:_ -> f s
          _ -> error $ "Error: " ++ c ++ " expected an argument."
        binary f s = case s of
          x:y:_ -> f s
          _ -> error $ "Error: " ++ c ++ " expected two arguments."
```
Здесь используется тотальный парсер `readMaybe` из модуля `Text.Read`. Можно было бы привести программу и раза в два короче, но уже без информативных сообщениях об ошибках, а это некрасиво.
</spoiler>

Прекрасное начало для разговора! Далее, как правило, начинают навешивать эффекты: меняют свёртку `foldl` на `foldM`, обеспечивают тотальность через монаду `Either String`, потом добавляют логирование, оборачивая всё трасформером `WriterT`, внедряют с помощью `StateT`  словарь для переменных, и так далее. Иногда, для демонстрации крутости монадических вычислений, реализуют неоднозначный калькулятор, возвращающий все возможные значения выражения $inline$(2 \pm 3)*((4 \pm 8)\pm 5)$inline$. Это долгий, хороший и интересный разговор. Однако, свой рассказ мы сразу поведём по-другому, хотя закончим его тем же результатом.

Почему, вообще, речь заходит о свёртке? Потому что свёртка (катаморфизм) -- это абстракция последовательной обработки индуктивных данных. Стековая машина линейно проходит по коду, выполняя последовательность инструкций и порождает одно значение -- состояние стека. Мне нравится представлять себе работу свёрточной стековой машины, как трансляцию матричной РНК в живой клетке. Рибосома шаг за шагом проходит всю цепочку РНК, сопоставляет триплеты нуклеотидов с аминокислотами и [создаёт](https://youtu.be/8dsTvBaUMvw) первичную структуру белка. 

У свёрточной машины есть ряд ограничений, основное -- программа всегда прочитывается от начала до конца и один раз. Ветвление, циклы и вызовы подпрограмм требуют концептуального изменения интерпретатора. Ничего сложного, конечно, но такая машина уже не может быть описана простой свёрткой.

Согласно гипотезе лингвистической относительности, свойства используемого нами языка напрямую влияют на свойства нашего мышления. Давайте обратим внимание не на машину, а на *языки *и *программы*, которыми она управляется. Все стеково-ориентированные языки, как относительно низкоуровневые (байт-коды виртуальных машин Java и Python или .NET), так и языки уровнем повыше (PostScript, Forth или Joy), имеют одно фундаментальное общее свойство: если соединить, то есть, записать последовательно две корректные программы, то получится корректная программа. Правда, корректная не значит "правильная", эта программа может вылетать с ошибкой на любых данных или проваливаться в бесконечные циклы и вообще не иметь смысла, но главное -- такая программа сможет быть выполнена машиной. В то же время, разбивая корректную программу на части мы легко можем эти части использовать повторно, именно в силу их корректности. Наконец, в любом стековом языке можно выделить подмножество команд, оперирующих только внутренним состоянием машины (стеком или регистрами), не использующих какую-либо внешнюю память. Это подмножество будет образовывать язык, обладающий свойством *конкатенативности*. В таком языке любая программа имеет смысл преобразователя состояния, а последовательное выполнение программ эквивалентно их композиции, а значит, тоже является преобразователем состояния.

Просматривается общий паттерн: комбинация (конкатенация) корректных программ порождает корректную программу, комбинация преобразователей порождает преобразователь. Получается, что программы стековых языков *замкнуты относительно операции конкатенации* или образуют структуру, которая называется *группоидом* или *магмой*. То есть, можно, записав программу на ленту, ножницами разрезать её почти как попало и потом из полученных отрезков формировать новые программы. Причём разрезать можно вплоть до отрезков с единственной инструкцией.

При склеивании важен порядок: две программы $inline$\texttt{5 dup pop}$inline$ и $inline$\texttt{5 pop dup}$inline$, несомненно, разные. Зато неважно где программу разрезать, если тут же её в этом месте склеить. Например, программа $inline$\texttt{5 dup} + \texttt{pop}$inline$ эквивалентна программе $inline$\texttt{5} + \texttt{dup pop}$inline$.  Это простое обстоятельство отражает *ассоциативность* операции конкатенации и поднимает структуру, которую образуют стековые программы, на новый уровень, мы понимаем что это *полугруппа*!

И что это нам даёт, как программистам? Ассоциативность позволяет выполнять прекомпиляцию, оптимизацию и даже распараллеливание произвольных пригодных для этого отрезков программы, а потом объединять их в эквивалентную программу. Мы можем позволить себе провести статический анализ любого отрезка программы и использовать его в анализе всей программы именно потому, что нам всё равно, где ставить скобки. Это очень важные и серьёзные возможности для языка низкого уровня или промежуточного языка, на котором пишет не человек, а транслятор. А с точки зрения математика и матёрого функциональщика, это делает программы-преобразователи состояния машины полноценными *эндоморфизмами*, -- отображениями множества состояний в себя. Эндоморфизмы тоже образуют полугруппу с операцией композиции. 

"Полугруппа" звучит половинчато, как-то неполноценно. Может быть, стековые программы образуют группу? *Группой* является множество, замкнутое относительно ассоциативной бинарной операции, причём для этой операции имеется нейтральный элемент, и каждый элемент множества имеет обратный.

Э.. нет, большинство программ необратимо, то есть, по результату выполнения не выйдет однозначно восстановить исходные данные. А вот нейтральный элемент у нас есть. В языках ассемблера он обозначается $inline$\texttt{nop}$inline$ и ничего не делает. Если в стековом языке такого оператора явно не определили, то его можно легко получить комбинируя некоторые команды, например: $inline$\texttt{inc dec}$inline$, $inline$\texttt{dup pop}$inline$ или $inline$\texttt{swap swap}$inline$. Такие пары можно безболезненно вырезать из программ или, напротив, вставлять куда угодно в произвольном количестве. Поскольку единица имеется, наши программы образуют *полугруппу с единицей* или *моноид*. Значит, можно программно реализовать их в виде моноидов -- эндоморфизмов над состоянием стековой машины. Это позволит определить небольшой набор базовых операций для машины, а потом создавать программы с помощью их композиции, получив стековый язык в форме EDSL (встроенного предметно-ориентированного языка).

В языке Haskell пулугруппы и моноиды описаны с помощью классов `Semigroup` и `Monoid`. Их опредления просты и отражают математический смысл этих структур, за исключением требования ассоциативности:

```haskell
class Semigroup a where
  (<>) :: a -> a -> a

class Semigroup a => Monoid a where
  mempty :: a
```

###Строим машину

<spoiler title="Заголовочная часть программы">
```haskell
{-# LANGUAGE LambdaCase, GeneralizedNewtypeDeriving #-}

import Data.Semigroup (Max(..),stimes)
import Data.Monoid
import Data.Vector ((//),(!),Vector)
import qualified Data.Vector as V (replicate)
```
</spoiler>

Мы сразу построим машину, которая располагает стеком, конечной памятью и умеет аварийно останавливаться по-хорошему, чистым образом. Всё это реализуем без использования монад,  инкапсулировав необходимые данные в тип, описывающий машину. Таким образом, все базовые программы, а значит и все их комбинации будут чистыми преобразователями её состояния.

Начнём с определения типа для виртуальной машины и тривиальных функций-сеттеров. 
```haskell
type Stack = [Int]
type Memory = Vector Int
type Processor = VM -> VM

memSize = 4

data VM = VM { stack :: Stack
             , status :: Maybe String
             , memory :: Memory }
          deriving Show

emptyVM = VM mempty mempty (V.replicate memSize 0)

setStack :: Stack -> Processor
setStack  x (VM _ s m) = VM x s m

setStatus :: Maybe String -> Processor
setStatus x (VM s _ m) = VM s x m

setMemory :: Memory -> Processor
setMemory x (VM s st _) = VM s st x
```
Сеттеры нужны для того, чтобы сделать явной семантику программы. Под процессором (тип `Processor`) мы будем понимать преобразователь `VM -> VM`. 

Теперь определим тип-обёртку для программы:
```haskell
newtype Program = Program { getProgram :: Dual (Endo VM) }
  deriving (Semigroup, Monoid)
```
Типы-обёртки `Endo` и `Dual` определяют принцип композиции программ: это эндоморфизмы с обратным порядком композиции (слева направо).  Использование обёрток позволяет компилятору самостоятельно определить каким образом тип `Program` реализует требования классов `Semigroup` и `Monoid`.

Исполнитель программ тривиален:
```haskell
run :: Program -> Processor
run = appEndo . getDual . getProgram

exec :: Program -> VM
exec prog = run prog emptyVM
```
Сообщение об ошибке будет формировать функция `err`:
```haskell
err :: String -> Processor
err = setStatus . Just $ "Error! " ++ m
```
Мы используем тип `Maybe` не так как он используется обычно: пустое значение `Nothing` в статусе означает, что ничего опасного не происходит, и вычисления можно продолжать, в свою очередь, строковое значение знаменует проблемы. Для удобства, определим два умных конструктора: один -- для программ, работающих только со стеком, другой -- для тех, которым нужна память.
```haskell
program :: (Stack -> Processor) -> Program
program f = Program . Dual . Endo $
  \vm -> case status vm of
    Nothing -> f (stack vm) vm
    _ -> vm

programM :: ((Memory, Stack) -> Processor) -> Program
programM f = Program . Dual . Endo $
  \vm -> case status vm of
    Nothing -> f (memory vm, stack vm) vm
    _ -> vm
```
 Теперь можно определять базовые команды языка для работы со стеком и памятью, целочисленную арифметику, а также отношения эквивалентности и порядка.

<spoiler title="Работа со стеком">
```haskell
pop = program $ 
  \case x:s -> setStack s
        _ -> err "pop expected an argument."

push x = program $ \s -> setStack (x:s)

dup = program $ 
  \case x:s -> setStack (x:x:s)
        _ -> err "dup expected an argument."

swap = program $ 
  \case x:y:s -> setStack (y:x:s)
        _ -> err "swap expected two arguments."

exch = program $ 
  \case x:y:s -> setStack (y:x:y:s)
        _ -> err "exch expected two arguments."
```
</spoiler>

<spoiler title="Работа с памятью">
```haskell
-- конструктор для функций с ограниченным индексом
indexed i f = programM $ if (i < 0 || i >= memSize)
                         then const $ err "exprcted index in [0,8]"
                         else f

put i = indexed i $
    \case (m, x:s) -> setStack s . setMemory (m // [(i,x)])
          _ -> err "put expected an argument"

get i = indexed i $ \(m, s) -> setStack ((m ! i) : s)
```
</spoiler>

<spoiler title="Арифметические операции и отношения">
```haskell
unary n f = program $
  \case x:s -> setStack (f x:s)
        _ -> err $ "operation " ++ show n ++ " expected an argument"

binary n f = program $
  \case x:y:s -> setStack (f x y:s)
        _ -> err $ "operation " ++ show n ++ " expected two arguments"

add = binary "add" (+)
sub = binary "sub" (flip (-))
mul = binary "mul" (*)
frac = binary "frac" (flip div)
modulo = binary "modulo" (flip mod)
neg = unary "neg" (\x -> -x)
inc = unary "inc" (\x -> x+1)
dec = unary "dec" (\x -> x-1)
eq = binary "eq" (\x -> \y -> if (x == y) then 1 else 0)
neq = binary "neq" (\x -> \y -> if (x /= y) then 1 else 0)
lt = binary "lt" (\x -> \y -> if (x > y) then 1 else 0)
gt = binary "gt" (\x -> \y -> if (x < y) then 1 else 0)
```
</spoiler>

Для полноценной работы не хватает ветвления и циклов. Вообще-то, для встроенного языка достаточно только ветвления, циклы можно организовать с помощью рекурсии, но мы сделаем наш язык самодостаточным. Кроме того, воспользуемся тем, что программы образуют полугруппу и определим комбинатор повторения программы указанное число раз. Количество повторений он будет брать со стека.

<spoiler title="Ветвление и циклы">
```haskell
proceed :: Program -> Stack -> Processor
proceed prog s = run prog . setStack s

branch :: Program -> Program -> Program
branch br1 br2 = program go
   where go (x:s) = proceed (if (x /= 0) then br1 else br2) s
         go _ = err "branch expected an argument."

while :: Program -> Program -> Program
while test body = program (const go) 
  where go vm = let res = proceed test (stack vm) vm
          in case (stack res) of
               0:s -> proceed mempty s res
               _:s -> go $ proceed body s res
               _ -> err "while expected an argument." vm

rep :: Program -> Program
rep body = program go
  where go (n:s) = proceed (stimes n body) s
        go _ = err "rep expected an argument."
```
</spoiler>
Типы функций `branch` и `while` говорят о том, что это не самостоятельные программы, а комбинаторы программ: типичный подход при создании EDSL в Haskell. Функция `stimes` определена для всех полугрупп, она возвращает композицию указанного числа элементов.

Наконец, напишем несколько программ, для опытов.
<spoiler title="Примеры программ">
```haskell
-- рекурсивный факториал
fact = dup <> push 2 <> lt <>
       branch (push 1) (dup <> dec <> fact) <>
       mul

-- итеративный факториал
fact1 = push 1 <> swap <>
        while (dup <> push 1 <> gt) 
        (
	     swap <> exch <> mul <> swap <> dec
        ) <> 
	    pop

-- заполняет стек последовательностью чисел
-- в указанном диапазоне
range = exch <> sub <> rep (dup <> inc)

-- ещё один итеративный факториал,
-- записанный через свёртку списка команд
fact2 = mconcat [ dec, push 2, swap, range, push 3, sub, rep mul]

-- итеративный факториал с использованием памяти
fact3 = dup <> put 0 <> dup <> dec <>
        rep (dec <> dup <> get 0 <> mul <> put 0) <>
        get 0 <> swap <> pop

-- копирует два верхних элемента стека
copy2 = exch <> exch

-- вычисляет наибольший общий делитель 
-- по простейшему алгоритму Евклида
gcd1 = while (copy2 <> neq) 
       (
         copy2 <> lt <> branch mempty (swap) <> exch <> sub
       ) 
       <> pop
	   
-- возведение в степень методом русского крестьянина
pow = swap <> put 0 <> push 1 <> put 1 <>
      while (dup <> push 0 <> gt)
      (
        dup <> push 2 <> modulo <>
        branch (dec <> get 0 <> dup <> get 1 <> mul <> put 1) (get 0) <>
        dup <> mul <> put 0 <>
        push 2 <> frac
      ) <>
      pop <> get 1
	   
```
</spoiler>
Получилось 120 строк кода с комментариями и аннотациями типов, которые определяют машину, оперирующую 18 командами с тремя комбинаторами. Вот как наша машина работает .

```haskell
λ> exec (push 6 <> fact)
VM {stack = [720], status = Nothing, memory = [0,0,0,0]}
λ> exec (push 6 <> fact3)
VM {stack = [720], status = Nothing, memory = [720,0,0,0]}
λ> exec (push 2 <> push 6 <> range)
VM {stack = [6,5,4,3,2], status = Nothing, memory = [0,0,0,0]}
λ> exec (push 6 <> push 9 <> gcd1)
VM {stack = [3], status = Nothing, memory = [0,0,0,0]}
λ> exec (push 3 <> push 15 <> pow)
VM {stack = [14348907], status = Nothing,  memory = [43046721,14348907,0,0]}
λ> exec (push 9 <> gcd1)
VM {stack = [9], status = Just "Error! exch expected two arguments", memory = [0,0,0,0]}
```

На самом деле, мы ничего нового не сделали -- комбинируя преобразователи-эндоморфизмы, мы, по существу, вернулись к свёртке, но она стала неявной. Напомним, свёртка даёт абстракцию последовательной обработки индуктивных данных. Данные, в нашем случае, образуются индуктивным образом при склеивании программ оператором $inline$\diamond$inline$, и "хранятся" они в эндоморфизме в виде цепочки композиций функций-преобразователей машины до момента применения этой цепочки к исходному состоянию. В случае применения комбинаторов `branch` и `while` цепочка начинает превращаться в дерево или в цикл. В общем случае, мы получаем граф, отражающий работу автомата с магазинной памятью, то есть, стековой машины. Именно эту структуру мы "сворачиваем" при выполнении программы.

Насколько эффективна такая реализация? Композиция функций -- это самое лучшее, что умеет делать компилятор языка Haskell. Он, буквально, рождён для этого! Когда речь заходит о преимуществах использования знания о моноидах, часто приводят пример разностных списков `diffList` -- реализации связного списка в виде композиции эндоморфизмов. Разностные списки принципиально ускоряют формирование списков из множества кусочков благодаря ассоциативности композиции функций. Возня с типами-обёртками не приводит к увеличению накладных расходов, они "растворяются" на этапе компиляции. Из лишней работы остаётся только проверка состояния на каждом шаге выполнения программы.

###Комбинируем моноиды

Думаю, к этому моменту скептики и случайные читатели уже нас покинули, можно позволить себе расслабиться и перейти на следующий уровень абстракции. Концепция полугрупп и моноидов не была бы столь полезной и универсальной, если бы не ряд свойств, присущих всем полугруппам и моноидам без исключения, которые позволяют из простых структур строить сложные точно таким же образом, каким мы строим сложные программы из простых. Эти свойства относятся уже не к объектам, а к типам и их лучше записать не в математической нотации, а в виде программ на Haskell, которые в силу изоморфизма Карри-Ховарда, являются их доказательствами.

1. Моноиды и полугруппы можно "перемножать". Здесь имеется в виду произведение типов, абстракцией которого в Haskell является кортеж или пара. 

```haskell
instance (Semigroup a, Semigroup b) => Semigroup (a,b) where
    (a1, b1) <> (a2, b2) = (a1 <> a2, b1 <> b2)
instance (Monoid a, Monoid b) => Monoid (a,b) where
    mempty = (mempty, mempty )
```

2. Существует единичный моноид, он представлен единичным типом `()`:

```haskell
instance Semigroup () where
    () <> () = ()
instance Monoid () where
    mempty = ()
```

С операцией перемножения полугруппы сами образуют полугруппу, а принимая во внимание единичный тип, можно сказать, что моноиды образуют моноид! Ассоциативность и нейтральность единицы при этом выполняется с точностью до изоморфизма, но это не принципиально.

3. Отображения в полугруппу или моноид образуют, соответственно, полугруппу или моноид. И тут тоже проще записать это утверждение на Haskell:

```haskell
instance Semigroup a => Semigroup (r -> a) where
  f <> g = \r -> f r <> g r
instance Monoid a => Monoid (r -> a) where
  mempty = const mempty
```

3. Для любого моноида существует дуальный ему моноид, отличающийся порядком комбинирования:

```haskell
instance Semigroup a => Semigroup (Dual a) where
  Dual a <> Dual b = Dual (b <> a)
instance Monoid a => Monoid (Dual a) where
  mempty = Dual mempty
```

Дуальность мы уже использовали. Этот простой тип-обёртка, оказывается, важная птица, он один из комбинаторов для типов-моноидов.

Воспользуемся этими комбинаторами для того, чтобы расширить возможности построенного нами стекового языка. Давайте внесём серьёзное изменение и сделаем наши базовые команды *функциями, возвращающими программы*. Это не лишит их моноидальных свойств, зато позволит вводить в работу всех команд машины произвольную информацию извне. Вот что имеется ввиду:
```haskell
(command1 <> command2) r   ==  command1 r <> command2 r
```
Информация может быть любой, например, внешний словарь с какими-то определениями, или например, способ вести журнал вычислений, нужный при отладке. Это очень похоже на действие монады `Reader`, которая, как раз, и является просто функцией.

Мы введём в структуру машины журнал, но не будем привязывать его к какому-то определённому типу, а выведем его в параметр типа.
```haskell
data VM j = VM { stack :: Stack
               , status :: Maybe String
               , memory :: Memory
               , journal :: j }
            deriving Show

mkVM = VM mempty mempty (V.replicate memSize 0)

setStack  x (VM _ st m l) = VM x st m l
setStatus st (VM s _ m l) = VM s st m l
setMemory m (VM s st _ l) = VM s st m l
addRecord x (VM s st m j) = VM s st m (x<>j)

newtype Program j = Program { getProgram :: Dual (Endo (VM j)) }
  deriving (Semigroup, Monoid)
```
С этого момента я позволю себе не писать аннотации типов, предоставляя компилятору разбираться с ними самостоятельно, они не сложные, хоть и становятся громоздкими. Сами команды менять не придётся, благодаря умным конструкторам, которые примут на себя все изменения. Совсем небольшие.

<spoiler title="Новые конструкторы и комбинаторы.">
```haskell
program f p = Program . Dual . Endo $
  \vm -> case status vm of
    Nothing -> p . (f (stack vm)) $ vm
    m -> vm

programM f p = Program . Dual . Endo $
  \vm -> case status vm of
    Nothing -> p . (f (memory vm, stack vm)) $ vm
    m -> vm

proceed p prog s = run (prog p) . setStack s

rep body p = program go id
  where go (n:s) = proceed p (stimes n body) s
        go _ = err "rep expected an argument."

branch br1 br2 p = program go id
   where go (x:s) = proceed p (if (x /= 0) then br1 else br2) s
         go _ = err "branch expected an argument."

while test body p = program (const go) id
  where go vm = let res = proceed p test (stack vm) vm
          in case (stack res) of
               0:s -> proceed p mempty s res
               _:s -> go $ proceed p body s res
               _ -> err "while expected an argument." vm
```
</spoiler>

Осталось научить вводить внешнюю информацию в исполнитель программ. Это очень просто сделать, создавая различные исполнители с различной стратегией ведения журнала. Первый исполнитель будет самым простым, молчаливым, не тратящим сил на ведение журнала:
```haskell
exec prog = run (prog id) (mkVM ())
```
Тут нам пригодился единичный моноид `()`. Далее, можно определить функцию для исполнителя, готового записывать в журнал ту или иную информацию о состоянии машины.
```haskell
execLog p prog = run (prog $ \vm -> addRecord (p vm) vm) (mkVM mempty)
```
Информация может быть, например, такая:
```haskell
logStack vm   = [stack vm]
logStackUsed  = Max . length . stack
logSteps      = const (Sum 1)
logMemoryUsed = Max . getSum . count . memory
  where count = foldMap (\x -> if x == 0 then 0 else 1)
```
Проверяем работу:
```haskell
λ> exec (push 4 <> fact2)
VM {stack = [24], status = Nothing, memory = [0,0,0,0], journal = ()}
λ>  journal $ execLog logSteps (push 4 <> fact2)
Sum {getSum = 14}
 mapM_ print $ reverse $ journal $ execLog logStack (push 4 <> fact2)
[4]
[3]
[2,3]
[3,2]
[2,2]
[3,2]
[3,3,2]
[4,3,2]
[4,4,3,2]
[5,4,3,2]
[3,5,4,3,2]
[2,4,3,2]
[12,2]
[24]
```
Логгеры можно комбинировать, пользуясь тем обстоятельством, что моноиды перемножаются. Введём простой комбинатор для логгеров:
```haskell
f &&& g = \r -> (f r, g r)
```
Так можно провести сравнение четырёх реализаций факториала по числу шагов и максимальной длине стека
```haskell
λ> let report p = journal $ execLog (logSteps &&& logStackUsed) p
λ> report (push 8 <> fact)
(Sum {getSum = 48},Max {getMax = 10})
λ> report (push 8 <> fact1)
(Sum {getSum = 63},Max {getMax = 4})
λ> report (push 8 <> fact2)
(Sum {getSum = 26},Max {getMax = 9})
λ> report (push 8 <> fact3)
(Sum {getSum = 43},Max {getMax = 3})
```
Логгеры можно было бы объявить моноидом с операцией `&&&`, если бы они все возвращали одинаковый тип. Но так как они разные, Haskell это сделать не позволяет. Так что не всё, что комбинируется является работающим моноидом.

###Освобождение моноида

А если мы захотим выполнять программы совсем по-другому? Скажем, напечатать код программы, провести анализ, передать другому исполнителю... Наши программы -- это функции, у них нет имени вне пространства имён Haskell. И тут мы приходим к красивому рассуждению. 

Можно сопоставить каждой базовой команде уникальный код, в то же время, можно сопоставить коду -- команду. Оба соответствия однозначные, а значит: множества команд и имён *изоморфны*. Программы (комбинации команд) образуют моноид, и тексты программ (последовательность кодов) образуют моноид. Мы и начинали разговор с того, что разрезали и склеивали именно *тексты* программ, записанные на лентах. Значит между программами и их кодами можно построить *гомоморфизмы* -- отображения одного моноида в другой, сохраняющее алгебраическую структуру.

Давайте же сделаем его! Определим сначала тип для кодов нашего языка:

```haskell
data Code = IF [Code] [Code]
          | REP [Code]
          | WHILE [Code] [Code]
          | PUT Int | GET Int
          | PUSH Int | POP | DUP | SWAP | EXCH
          | INC | DEC | NEG
          | ADD | MUL | SUB | DIV
          | EQL | LTH | GTH | NEQ
          deriving (Read, Show)
```

Теперь построим гомоморфизм код $inline$\rightarrow$inline$ программа:
```haskell
fromCode = foldMap $  
  \case
    IF b1 b2 -> branch (fromCode b1) (fromCode b2)
    REP p -> rep (fromCode p)
    WHILE t b -> while (fromCode t) (fromCode b)
    PUT i -> put i
    GET i -> get i
    PUSH i -> push i
    POP -> pop
    DUP -> dup
    SWAP -> swap
    EXCH -> exch
    INC -> inc
    DEC -> dec
    ADD -> add
    MUL -> mul
    SUB -> sub
    DIV -> frac
    EQL -> eq
    LTH -> lt
    GTH -> gt
    NEQ -> neq
    NEG -> neg
```
Здесь мы используем то, что программы являются моноидами: свёртка `foldMap` это эффективная свёртка, рассчитанная на моноиды и использующая ассоциативность моноиданых операций. Этот гомоморфизм является транслятором программы, записанной в кодах. Он уже позволяет транслировать программы, записанные в виде кодов и даже в виде текcта:

```haskell
λ> stack $ exec (fromCode [PUSH 2, PUSH 5, EXCH, SUB, REP [DUP, INC]])
[5,4,3,2]
λ> stack $ exec (fromCode $ read "[PUSH 2, PUSH 5, EXCH, SUB, REP [DUP, INC]]")
[5,4,3,2]
```

Обратный гомоморфизм *программа *$inline$\rightarrow$inline$* код* построить таким же образом не выйдет, поскольку мы не можем перебирать в `case` функции. Но можно снова воспользоваться двумя замечательными обстоятельствами: тем что программы образуют моноид и тем что моноиды образуют полугруппу! Перемножим в определении типа `Program` код программы и соответствующий ему трансформер:

```haskell
newtype Program a = Program { getProgram :: ([Code], Dual (Endo (VM a))) }
  deriving (Semigroup, Monoid)
```
Наряду с исполняющей функцией `run` появляется возможность получить код программы
```haskell
run = appEndo . getDual . snd . getProgram
toCode prog = fst . getProgram $ prog id
```
Теперь остаётся переписать выражения для умных конструкторов так, чтобы каждой базовой программе можно было бы указать её код. Впрочем, конструкторы и определения команд языка изменятся не существенно:
```haskell
program c f p = Program . ([c],) . Dual . Endo $
  \vm -> case status vm of
    Nothing -> p . (f (stack vm)) $ vm
    _ -> vm

programM c f p = Program . ([c],) . Dual . Endo $
  \vm -> case status vm of
    Nothing -> p . (f (memory vm, stack vm)) $ vm
    _ -> vm
```

<spoiler title="Определения именованных базовых команд и комбинаторов">
```haskell
pop = program POP $ 
  \case x:s -> setStack s
        _ -> err "POP expected an argument."

push x = program (PUSH x) $ \s -> setStack (x:s)

dup = program DUP $ 
  \case x:s -> setStack (x:x:s)
        _ -> err "DUP expected an argument."

swap = program SWAP $ 
  \case x:y:s -> setStack (y:x:s)
        _ -> err "SWAP expected two arguments."

exch = program EXCH $ 
  \case x:y:s -> setStack (y:x:y:s)
        _ -> err "EXCH expected two arguments."

app1 c f = program c $
  \case x:s -> setStack (f x:s)
        _ -> err $ "operation " ++ show c ++ " expected an argument"

app2 c f = program c $
  \case x:y:s -> setStack (f x y:s)
        _ -> err $ "operation " ++ show c ++ " expected two arguments"

add = app2 ADD (+)
sub = app2 SUB (flip (-))
mul = app2 MUL (*)
frac = app2 DIV (flip div)
neg = app1 NEG (\x -> -x)
inc = app1 INC (\x -> x+1)
dec = app1 DEC (\x -> x-1)
eq = app2 EQL (\x -> \y -> if (x == y) then 1 else 0)
neq = app2 NEQ (\x -> \y -> if (x /= y) then 1 else 0)
lt = app2 LTH (\x -> \y -> if (x > y) then 1 else 0)
gt = app2 GTH (\x -> \y -> if (x < y) then 1 else 0)

proceed p prog s = run (prog p) . setStack s

rep body p = program (REP (toCode body)) go id
  where go (n:s) = if n >= 0
                   then proceed p (stimes n body) s
                   else err "REP expected positive argument."
        go _ = err "REP expected an argument."

branch br1 br2 p = program (IF (toCode br1) (toCode br2)) go id
   where go (x:s) = proceed p (if (x /= 0) then br1 else br2) s
         go _ = err "IF expected an argument."

while test body p = program (WHILE (toCode test) (toCode body)) (const go) id
  where go vm = let res = proceed p test (stack vm) vm
          in case (stack res) of
               0:s -> proceed p mempty s res
               _:s -> go $ proceed p body s res
               _ -> err "WHILE expected an argument." vm

put i = indexed (PUT i) i $
    \case (m, x:s) -> setStack s . setMemory (m // [(i,x)])
          _ -> err "PUT expected an argument"

get i = indexed (GET i) i $ \(m, s) -> setStack ((m ! i) : s)

indexed c i f = programM c $ if (i < 0 || i >= memSize)
                             then const $ err "index in [0,16]"
                             else f
```
</spoiler>

Всё, изоморфизм между программами и их кодами установлен! Давайте посмотрим, как он работает:

```haskell
λ>  toCode fact1
[PUSH 1,SWAP,WHILE [DUP,PUSH 1,GTH] [SWAP,EXCH,MUL,SWAP,DEC],POP]
λ>  toCode gcd1
[WHILE [EXCH,EXCH,NEQ] [EXCH,EXCH,LTH,IF [] [SWAP],EXCH,SUB],POP]
λ> toCode $ fromCode [PUSH 5, PUSH 6, ADD]
[PUSH 5, PUSH 6, ADD]
λ> exec (fromCode $ toCode (push 5 <> push 6 <> add))
VM {stack = [11], status = Nothing, memory = [0,0,0,0], journal = ()}
```
В последних двух примерах демонстрируется, что два гомоморфизма `toCode` и `fromCode` являются взаимообратными. Теперь программы можно создавать с помощью EDSL, записывать их в файл и считывать из него. 

Правда, наш изоморфизм имеет один существенный недостаток: он не позволяет превратить в конечный код программы, определённые с помощью рекурсии. Попробуйте в ghci посмотреть код программы `fact`, только держите пальцы на готове, чтобы поскорее нажать `Ctrl+C`.

Код программы имеет вид дерева и он представляет собой чистую информацию о программе. Такая структура называется *свободной*. Свободным моноидом в самом общем смысле является список. Мы же получили *свободную алгебру* программ для нашей стековой машины. 

Кроме возможностей сериализации и десериализации свободные структуры предоставляют свободу интерпретации. Мы построили пока только один способ интерпретации свободной программы -- в виде трансформаций состояния стековой машины. Но имея программу в свободной форме можно делать с ними что угодно, например обеспечивать форматированный вывод, проводить оптимизацию или статический анализ.

###Примеры использования свободной программы

Обычно, на этом замечательном пассаже статьи про свободные структуры обрывается: можно и можно, правда сложно и в одном разделе не рассказать. Но так вышло, что наш язык чрезвычайно прост и чрезвычайно моноидален, а это позволяет делать некоторые вещт очень изящно. Грех этим не воспользоваться и не поделиться!

Вот, например, как просто написать форматированный вывод
```haskell
pprint = unlines . printCode 0 . toCode
  where
    printCode n = foldMap f
      where
        f = \case
          IF b1 b2 -> print "IF" <> indent b1 <> print ":" <> indent b2
          REP p -> print "REP" <> indent p
          WHILE t b -> print "WHILE" <> indent t <> indent b
          c -> print $ show c

        print x = [stimes n "  " ++ x]
        indent = printCode (n+1)
```

И снова строится гомоморфизм: теперь командам ставятся в соответствие строки с отступом, которые, опять же, образуют моноид. 
<spoiler title="Пара симпатично напечатанных программ:">
```haskell
λ> putStrLn $ pprint fact2
INC
PUSH 1
SWAP
EXCH
SUB
DUP
PUSH 0
GTH
IF
  REP
    DUP
    INC
:
  NEG
  REP
    DUP
    DEC
DEC
DEC
REP
  MUL

λ> putStrLn $ pprint gcd1
WHILE
  EXCH
  EXCH
  NEQ
  EXCH
  EXCH
  LTH
  IF
  :
    SWAP
  EXCH
  SUB
POP
```
</spoiler>

Не будем на этом останавливаться и попробуем провесть нехитрый статический анализ программ для стековой машины. Тип данных у нас один, так что статическая типизация для языка не актуальна. Зато на стеке может не хватить данных для выполнения программы, но есть возможность вычислить максимальные требования для её работы до её выполнения.

Введём такую характеристику программ, как *арность *-- это информация о максимальном количестве аргументов, которые должны быть на стеке перед её выполнением и о минимальном числе элементов которые останутся на стеке после её выполнения. Например перед выполнением операции сложения нужно иметь на стеке не менее двух элементов, а после выполнения останется как минимум один элемент. Мы запишем это обстоятельство в таком виде:$$display$$\mathrm{arity}(\texttt{add}) =  2 \triangleright 1$$display$$ Приведём арности некоторых других операторов:$$display$$\mathrm{arity}(\texttt{push}) = 0 \triangleright 1\\ \mathrm{arity}(\texttt{pop}) =  1 \triangleright 0\\ \mathrm{arity}(\texttt{exch}) =  2 \triangleright 3$$display$$Почему мы всё время оговариваемся: минимальное число, максимальные требования..? Дело в том, что все базовые операторы имеют точно определённую арность, но при ветвлении разные ветви могут иметь разные требования и результаты. Наша задача: вычислить наиболее строгие требования, которые должны обеспечить работу всех ветвей, сколько бы их ни было.

При последовательном выполнении команд арности комбинируются следующим нетривиальным образом: $$display$$(i_1 \triangleright o_1) \diamond (i_2 \triangleright o_2) =  (a+i_1) \triangleright (a + o_1 + o_2 - i_2),\qquad a = \max(0, i_2 - o_1).$$display$$ Эта операция ассоциативна и имеет нейтральный элемент, что не удивительно для статьи, посвящённой моноидам. Добавим этот результат в программу:

```haskell
infix 7 :>
data Arity = Int :> Int deriving (Show,Eq)

instance Semigroup Arity where
  (i1 :> o1) <> (i2 :> o2) = let a = 0 `max` (i2 - o1)
                             in (a + i1) :> (a + o1 + o2 - i2)

instance Monoid Arity where
  mempty = 0:>0
```
А после этого можно строить гомоморфизм:

```haskell
arity = arity' . toCode
  where
    arity' = foldMap $
      \case
        IF b1 b2 -> let i1 :> o1 = arity' b1
                        i2 :> o2 = arity' b2
                    in 1:>0 <> (i1 `max` i2):>(o1 `min` o2)
        REP p -> 1:>0
        WHILE t b -> arity' t <> 1:>0
        PUT _ -> 1:>0
        GET _ -> 0:>1
        PUSH _ -> 0:>1
        POP -> 1:>0
        DUP -> 1:>2
        SWAP -> 2:>2
        EXCH -> 2:>3
        INC -> 1:>1
        DEC -> 1:>1
        NEG -> 1:>1
        _   -> 2:>1
```
Теперь можно рассчитать требования для любых программ:
```haskell
λ> arity (exch <> exch)
2 :> 4
λ> arity fact1
1 :> 1
λ> arity range
2 :> 1
```
От арности можно перейти, скажем, к тройкам Хоара и формально верифицировать программы, выводя пред- и постусловия для работы линейных участков (для циклов придётся возиться инвариантами).

###От моноидов к монадам и снова к моноидам

Но что если нашей машине нужно выйти в мир эффектов: общаться с пользователем, с файловой системой, базой данных, случайными числами и т.д.? Можно ли наше решение оснастить монадическими вычислениями? Можно и при том весьма просто! При использовании монады `m` преобразователи `VM -> VM` должны превратиться в `VM -> m VM`, это уже не эндоморфизм. Но вспомним крылатую фразу: "Монада -- это всего лишь моноид в категории эндофункторов, в чём проблемы?!" В категории Клейсли, которую образуют преобразователи `VM -> m VM` определена композиция, а она, согласно правилам категорий, ассоциативна и имеет нейтральный элемент. Эту композицию в Haskell обозначают оператором `>=>` и называют "рыбкой Клейсли". Значит, для выхода в мир вычислений с эффектами достаточно поменять начинку `Dual . Endo` на  моноид `Kleisli`, определив его следующим образом:
```haskell
newtype Kleisli m a = Kleisli {appKleisly :: a -> m a}

instance Monad m => Semigroup (Kleisli m a) where
  Kleisli f <> Kleisli g = Kleisli (f >=> g)
instance Monad m => Monoid (Kleisli m a) where
  mempty = Kleisli return
```
Поменяются сеттеры, они должны стать монадическими, и везде вместо их композиции (.) надо будет будет использовать оператор `>=>`. Все же прочие определения останутся без изменений. 

<spoiler title="Стековая машина с монадическими вычислениями">
```haskell
{-# LANGUAGE LambdaCase,GeneralizedNewtypeDeriving,TupleSections #-}

import Data.Semigroup (Max(..),stimes, Semigroup(..))
import Data.Monoid hiding ((<>))
import Data.Vector ((//),(!),Vector)
import qualified Data.Vector as V (replicate)
import Control.Monad

type Stack = [Int]
type Memory = Vector Int

memSize = 4

data VM a = VM { stack :: Stack
               , status :: Maybe String
               , memory :: Memory
               , journal :: a }
            deriving Show

mkVM = VM mempty mempty (V.replicate memSize 0)

setStack  x (VM _ st m l) = pure $ VM x st m l
setStatus st (VM s _ m l) = pure $ VM s st m l
setMemory m (VM s st _ l) = pure $ VM s st m l
addRecord x (VM s st m l) = VM s st m (x<>l)

------------------------------------------------------------

data Code = IF [Code] [Code]
          | REP [Code]
          | WHILE [Code] [Code]
          | PUT Int | GET Int
          | PUSH Int | POP | DUP | SWAP | EXCH
          | INC | DEC | NEG
          | ADD | MUL | SUB | DIV
          | EQL | LTH | GTH | NEQ
          | ASK | PRT | PRTS String 
          | FORK [Code] [Code]
          deriving (Read, Show)

newtype Kleisli m a = Kleisli {appKleisly :: a -> m a}

instance Monad m => Semigroup (Kleisli m a) where
  Kleisli f <> Kleisli g = Kleisli (f >=> g)
instance Monad m => Monoid (Kleisli m a) where
  mempty = Kleisli pure

newtype Program m a = Program { getProgram :: ([Code], Kleisli m (VM a)) }
  deriving (Semigroup, Monoid)

type Program' m a = (VM a -> m (VM a)) -> Program m a

program c f p = Program . ([c],) . Kleisli $
  \vm -> case status vm of
    Nothing -> p =<< f (stack vm) vm
    m -> pure vm

programM c f p = Program . ([c],) . Kleisli $
  \vm -> case status vm of
    Nothing -> p =<< f (memory vm, stack vm) vm
    m -> pure vm

run = appKleisly . snd . getProgram
toCode prog = fst . getProgram $ prog pure

err m = setStatus . Just $ "Error : " ++ m

exec prog = run (prog pure) (mkVM ())

execLog p prog = run (prog $ \vm -> pure $ addRecord (p vm) vm) (mkVM mempty)

f &&& g = \r -> (f r, g r)

logStack vm  = [stack vm]
logStackUsed = Max . length . stack
logSteps =  const (Sum 1)

logMemoryUsed :: VM a -> Max Int
logMemoryUsed =  Max . getSum . count . memory
  where count = foldMap (\x -> if x == 0 then 0 else 1)
 
------------------------------------------------------------

pop,dup,swap,exch :: Monad m => Program' m a
put,get,push :: Monad m => Int -> Program' m a
add,mul,sub,frac,inc,dec,neg :: Monad m => Program' m a
eq,neq,lt,gt :: Monad m => Program' m a

pop = program POP $ 
  \case x:s -> setStack s
        _ -> err "pop expected an argument."

push x = program (PUSH x) $ \s -> setStack (x:s)

dup = program DUP $ 
  \case x:s -> setStack (x:x:s)
        _ -> err "dup expected an argument."

swap = program SWAP $ 
  \case x:y:s -> setStack (y:x:s)
        _ -> err "swap expected two arguments."

exch = program EXCH $ 
  \case x:y:s -> setStack (y:x:y:s)
        _ -> err "expected two arguments."

put i = indexed (PUT i) i $
    \case (m, x:s) -> setStack s <=< setMemory (m // [(i,x)])
          _ -> err "put expected an argument"

get i = indexed (GET i) i $ \(m, s) -> setStack ((m ! i) : s)

indexed c i f = programM c $ if (i < 0 || i >= memSize)
                             then const $ err "index in [0,16]"
                             else f

app1 c f = program c $
  \case x:s -> setStack (f x:s)
        _ -> err $ "operation " ++ show c ++ " expected an argument"

app2 c f = program c $
  \case x:y:s -> setStack (f x y:s)
        _ -> err $ "operation " ++ show c ++ " expected two arguments"

add = app2 ADD (+)
sub = app2 SUB (flip (-))
mul = app2 MUL (*)
frac = app2 DIV (flip div)
neg = app1 NEG (\x -> -x)
inc = app1 INC (\x -> x+1)
dec = app1 DEC (\x -> x-1)
eq = app2 EQL (\x -> \y -> if (x == y) then 1 else 0)
neq = app2 NEQ (\x -> \y -> if (x /= y) then 1 else 0)
lt = app2 LTH (\x -> \y -> if (x > y) then 1 else 0)
gt = app2 GTH (\x -> \y -> if (x < y) then 1 else 0)

proceed p prog s = run (prog p) <=< setStack s

rep body p = program (REP (toCode body)) go pure
  where go (n:s) = if n >= 0
                   then proceed p (stimes n body) s
                   else err "rep expected positive argument."
        go _ = err "rep expected an argument."

branch br1 br2 p = program (IF (toCode br1) (toCode br2)) go pure
   where go (x:s) = proceed p (if (x /= 0) then br1 else br2) s
         go _ = err "branch expected an argument."

while test body p = program (WHILE (toCode test) (toCode body)) (const go) pure
  where go vm = do res <- proceed p test (stack vm) vm
                   case (stack res) of
                     0:s -> proceed p mempty s res
                     _:s -> go =<< proceed p body s res
                     _ -> err "while expected an argument." vm
```
</spoiler>

В рамках такой модели вычислений можно определить две новых команды: для считывания данных из `stdin` или с клавиатуры и для вывода значения либо сообщения на печать.

```haskell
ask, prt :: Program' IO a
ask = program ASK $
  \case s -> \vm -> do x <- getLine
                       setStack (read x:s) vm

prt = program PRT $
  \case x:s -> \vm -> print x >> return vm
        _ -> err "PRT expected an argument"

prtS :: String -> Program' IO a
prtS s = program (PRTS s) $
  const $ \vm -> print s >> return vm
```
Теперь можно написать что-то такое интерактивное и убедиться в том, что нам удалось совместить вычисления и эффекты:
```haskell
ioprog = prtS "input first number" <> ask
         <> prtS "input second number" <> ask
         <> rep (prt <> dup <> inc)
         <> prt
```
```haskell
λ> exec (ask <> ask <> rep (prt <> dup <> inc) <> prt)
input first number
3 
input second number
5 
3
4
5
6
7
8
VM {stack = [8,7,6,5,4,3], status = Nothing, memory = [0,0,0,0], journal = ()}
```

Для организации неоднозначных вычислений достаточно определить комбинатор, разветвляющий поток:

```haskell
fork :: Program' [] a -> Program' [] a -> Program' [] a
fork br1 br2 p = program (PM (toCode br1) (toCode br2)) (const go) pure
  where go = run (br1 p) <> run (br2 p)
```
Здесь опять сработала алгебра моноидов: функции `run` возвращают преобразователь `VM -> m VM`, их моноидальная композиция -- функцию, возвращающую композицию преобразователей, но теперь уже в рамках монады `[]`, то есть -- список вариантов.
Работает это вот так:
```haskell
λ> stack <$> exec (push 5 <> push 3 <> add `fork` sub)
[[8],[2]]
λ> stack <$> exec (push 5 <> push 3 `fork` dup <> push 2)
[[2,3,5],[2,5,5]]
```
Посчитаем пример из начала статьи: $inline$(2 \pm 3)*((4 \pm 8)\pm 5)$inline$:
```haskell
λ> let pm = add `fork` sub
λ> stack <$> exec (push 2 <> push 3 <> push 4 <> push 8 <> pm <> push 5 <> pm <> pm <> mul)
[[40],[-28],[20],[-8],[8],[4],[-12],[24]]
```
А вот сравнение эффективности четырёх реализаций факториалов:
```haskell
λ> journal <$> execLog logSteps (push 8 <> fact `fork` fact1 `fork` fact2 `fork` fact3)
[Sum {getSum = 48},Sum {getSum = 63},Sum {getSum = 34},Sum {getSum = 43}]
```
Записать выражение из четырёх ветвей вычислений без скобок нам позволило то, что программы образуют моноид с операцией `fork`, значит, операция `fork` ассоциативна.

$$display$$* * *$$display$$

Подведём итог. Построив EDSL на базе блоков-моноидов мы отразили основную особенность стековых языков -- их существенную конкатенативность. Кроме того, это позволило с помощью гомоморфизмов построить свободную алгебру для программ и реализовывать разнообразные интерпретаторы. С другой стороны, алгебраические свойства самих типов-моноидов позволяют манипулировать исполнителем, легко вводя в него дополнительный функционал.

С древне-греческого μάγμα переводится как грязь или тесто. Действительно, склеивая куски теста, мы вновь будем получать куски теста, которые можно склеивать. Это кажется более чем тривиальным наблюдением, но именно в этом заключается очарование пластилина или, например, конструктора Lego: благодаря универсальному интерфейсу соединение двух кубиков конструктора порождает новый кубик, готовый с кем-нибудь соединиться. С игрушками, соединяемыми липучками, например, так уже не получится. 

Кубики Lego позволяют мастерить то, что даже не могло прийти в голову их создателям, в то время как многие конструкторы не допускают расширения модели -- как на фабрике сделали, какую программу зашили, так и будет. И как ни соединяй, получится только то, что предусмотрено конструкцией либо неработающий хлам. С точки зрения защиты от дурака -- это замечательно! Но если серьёзно, то суть и ценность функционального программирования состоит именно в богатстве и гибкости комбинирования. Функции при комбинировании могут образовывать новые функции, которые снова можно по-разному комбинировать. Десятками лет люди не перестают находить новые комбинации (это и продолжения и пресловутые монады и линзы-профункторы) с полезными, а иногда и восхитительными свойствами. Но самое главное -- этот подход не прерогатива функционального программирования! В любой парадигме можно создавать жёсткие "одноразовые" блоки, громоздя из них фреймворки, требующие производство новых и новых блоков, поскольку они не комбинируются произвольным образом, либо создавать изящные расширяемые долгоживущие решения. Но именно в функциональной парадигме такие решения можно строить последовательно, доказывать и исследовать их свойства математически, оттачивать их прежде чем упаковывать в красивые и непрозрачные коробки и выпускать в мир технологий.
