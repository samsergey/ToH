<i>Продолжаю знакомить читателей Хабра с главами из своей книжки «Теория счастья» с подзаголовком «Математические основы законов подлости». Это ещё не изданная научно-популярная книжка, очень неформально рассказывающая о том, как математика позволяет с новой степенью осознанности взглянуть на мир и жизнь людей. Она для тех кому интересна наука и для тех, кому интересна жизнь. А поскольку жизнь наша сложна и, по большому счёту, непредсказуема, упор в книжке делается, в основном, на теорию вероятностей и математическую статистику. Здесь не доказываются теоремы и не даются основы науки, это ни в коем случае не учебник, а то, что называется recreational science. Но именно такой почти игровой подход позволяет развить интуицию, скрасить яркими примерами лекции для студентов и, наконец, объяснить нематематикам и нашим детям, что же такого интересного мы нашли в своей сухой науке.</i>

<spoiler title="Опубликованные главы:">
&emsp;•&ensp; <a href="https://habr.com/post/416941/">Введение в мерфологию</a>
&emsp;•&ensp; <a href="https://habr.com/post/416551/">Закон арбузной корки и нормальность ненормальности</a>
&emsp;•&ensp; <a href="https://habr.com/post/416907/">Закон зебры и чужой очереди</a>
&emsp;•&ensp; <a href="https://habr.com/post/421351/"> Проклятие режиссёра и проклятые принтеры</a>
&emsp;•&ensp; <a href="https://habr.com/post/424071/"> Термодинамика классового неравенства</a>
</spoiler>



<img src="https://habrastorage.org/webt/uy/di/md/uydimdifyol251xv0hnhtacosnc.gif" width="70%" align='center'/>

В этой главе мы порассуждаем о предопределённости полёта монетки, о топографических картах, о математических катастрофах и о природе случайности. А по пути заглянем в такие разделы математики, как теория мер и теория динамического хаоса.

<cut />

Разговор о законах подлости, как источнике житейских неурядиц, часто начинается со знаменитого <b>закона бутерброда</b>. Он просто формулируется, легко проверяется и широко известен:
<blockquote>Бутерброд всегда падает маслом вниз.</blockquote>
Понятно, что слово "всегда" здесь -- это преувеличение. Легко представить себе условия, в которых бутерброд упадет, оставив намазанную маслом сторону в сохранности. Что же люди понимают, под этим законом? Скорее всего, что бутерброд падает маслом вниз достаточно часто, чтобы это было заметно. Но чаще ли происходит неблагоприятный исход падения, чем благоприятный? Бутерброды разные, падают при различных обстоятельствах, с разной высоты... Параметров столько, что говорить о закономерностях в такой задаче, наверное, нет смысла. Всяко бывает. Бывает, что падает маслом вниз, тогда становится обидно, мы вспоминаем про закон и запоминаем его. А если бутерброд падает неинтересно -- маслом кверху, или если он оказался без масла вовсе, так и говорить не о чем -- понятно же, что закон-то шуточный! В конце концов, бутерброд подобен монетке, которую математики используют для получения случайных величин с двумя возможными значениями: "орёл" и "решка". Если монетка "честная", то ей абсолютно неважно какой стороной падать, и мы говорим, что вероятность падения орла и решки одинаковы и равны $inline$1/2$inline$. По идее, с бутербродами дела должны обстоять также. Мы вернёмся к ним в следующей главе, а пока присмотримся к самой, наверное, простой вероятностной системе -- к монетке.

Монетку в теоретиковероятностных экспериментах подбрасывают каким-то особым магическим образом, так чтобы выбор начального положения, начальной скорости и скорости закручивания при подбрасывании никак не влиял на вероятность конкретного исхода. Но очевидно же что это невозможно! Монетка представляет собой механическую систему и подчиняется законам механики, а они не содержат в себе случайных величин. Будущее в законах движения такого простого тела как монетка однозначно определяется прошлым состоянием этого тела. Если монетку будет подбрасывать робот, или демон Лапласа -- мифическое существо, обладающее полной информацией о координатах и скоростях любой механической системы, то при неизменных начальных данных, он будет получать идентичные результаты. Мы, конечно, не роботы и не демоны, но неужели люди подбрасывают монетки настолько неряшливо и непредсказуемо, что законы механики могут приводить к случайностям?

А откуда, вообще, берётся случайность в мире, описываемом законами механики? Откуда вообще, берётся случайность? В чём разница между истинно хаотическими или стохастическими системами, принципиально непредсказуемыми, и системами, в которых просто трудно угадать поведение, но его, в принципе, можно рассчитать?

Задача о монетке рассматривалась в 1986 году Джозефом Келлером. Мы приведём простое объяснение возникновению неопределённости в этом процессе, основанное на рассуждениях из статьи Келлера. То какой стороной упадёт монетка, зависит только от времени её полёта $inline$t$inline$ и от угловой скорости $inline$\omega$inline$. Если измерять угловую скорость в оборотах за единицу времени, то число оборотов, совершаемое монеткой, выражается предельно просто $inline$n = t \omega$inline$. Эта зависимость задаёт линии равного числа оборотов в координатах $inline$(t,\omega)$inline$, а они, в свою очередь, ограничивают области, соответствующие чётному и нечётному числу оборотов.

<img src="https://habrastorage.org/webt/2u/am/t-/2uamt-kpskdnr1qg0nkmsyywjyw.png" width="70%" align="center"/><i><font color="#444">Диаграмма, показывающая чётность количества оборотов, совершаемых монеткой в полёте. Прямоугольником показана область, в которой чаще всего происходит процесс гадания на монетке.</font></i>

На такой диаграмме можно показать каким будет результат подбрасывания монетки, закрученной на известное число оборотов в секунду, и пойманной через полсекунды после подбрасывания. Если попадаем в белую полоску, то выпадет та же сторона, что была сверху при подбрасывании, если в оранжевую -- обратная. Линии равного числа оборотов представляют собой гиперболы и видно, что по мере увеличения числа оборотов, чередование областей становится всё более и более частым, а сами области становятся тоньше. Человеческая рука несовершенна и очень небольшой разброс начальных значений перекрывает сразу много областей, делая исход непредсказуемым. В диапазоне действия руки (прямоугольник  на диаграмме) достаточно смещения на $inline$5\%$inline$ чтобы перескочить с белой полоски на оранжевую. Остаётся вопрос: а как из этого построения следует "честность" настоящей механической монеты? Как из полученной диаграммы получить вероятность выпадения орла или решки?

<h3>Срочно примите меру!</h3>
Окунёмся немного в такую математику, которую не проходят в школе, чтобы лучше понять о чём мы рассуждаем. Мы говорили во <abbr title="Введение к книжке, не вошло в цикл статей на Хабре.">введении</abbr>, что математики изучают не числа или геометрические фигуры, как может показаться после изучения школьного курса. Они работают с математическими структурами (абстрактными алгебрами, полукольцами, полями, моноидами, топологическими пространствами и прочей абстрактной всячиной), описывают их, как кажется, совершенно не привязываясь к практике, определяют их, изучают их свойства, доказывают теоремы. А потом оттачивают мастерство в поиске подобных структур в самых различных областях знаний, совершая удивительно полезные прорывы, в том числе в чисто прикладных отраслях. Мы сейчас немного коснёмся такой математики и рассмотрим как строится базис теории вероятностей, основанный на весьма абстрактном понятии меры.

Мы описали механику монетки и получили области, описывающие множества решений с определённым свойствами.  Области -- это плоские фигуры, как правильно перейти от них к вероятностям? Нам нужно измерять наши области и мы естественным образом приходим к их площади. Площадь -- является <i>мерой</i> плоской фигуры. Это точный математический термин, обозначающий функцию, ставящую в соответствие множеству некую неотрицательную числовую величину. Примерами мер являются <i>количества в перечислимых множествах</i> (количество яблок в мешке, например), а также <i>длины</i>, <i>площади</i>, <i>объёмы фигур</i>.

В математике существует целый раздел, который называется <i>теорий мер</i>. Эта теория родилась на рубеже IXX -- XX веков (у её истоков стояли  и открыла математикам широкие возможности для анализа очень сложно устроенных объектов: канторовых и фрактальных множеств. Она легла в основу функционального анализа и современной теории вероятностей, фундамент которой был заложен замечательным русским математиком Андреем Колмогоровым. Определение вероятности, как меры, позволяет увидеть все основные свойства вероятности как для дискретных, так и для непрерывных множеств.

Хотя наша книжка не учебник, но на этом стоит немного остановиться, чтобы взглянуть на понятия тории вероятностей как бы с "высоты птичьего полёта". Для начала перечислим основные свойства <i>любых</i> мер. Для того, чтобы лучше их представить, можно использовать вместо слова "мера" слова "количество" или "длина" либо "площадь".
<blockquote>1. Мера пустого множества равна нулю.
2. Мера подмножества не превышает меры множества
3. Мера объединения двух произвольных множеств равна сумме мер этих множеств за вычетом меры их пересечения (аддитивность).
4. Мера дополнения подмножества равна разности мер всего множества и меры подмножества.</blockquote>
Всякая ли неотрицательная числовая функция может быть мерой? Вовсе нет. Например, возраст ставит человеку в соответствие вполне определённое число. Но возраст двух людей нельзя определить, как сумму их возрастов. И скорость бега не является мерой -- два человека бегут не в два раза быстрее. А вот импульс (количество движения) или энергия уже обладают свойствами меры. Вес, количество денег, объём знаний, громкость крика хоть и не всегда легко измеримые вещи, но тоже могут служить мерой на множестве людей.

На интуитивном уровне с понятием вероятности знакомы сейчас, практически, все. Её оценивают политологи и журналисты на ток-шоу, её обсуждают говоря о глобальном потеплении или завтрашнем дожде, про неё рассказывают анекдоты
<blockquote>Какова вероятность встретить на Тверской динозавра? -- Одна вторая: либо встречу, либо нет
</blockquote> В современной математике понятие <i>вероятность</i> определяется, как мера на особом множестве. 

Давайте посмотрим, как общие свойства меры соотносятся с понятием вероятности. В качестве измеримого множества рассматривается <i>вероятностное пространство</i>, оно включает в себя как элементарные события, так и их комбинации, получаемые  объединением, пересечением и исключением. Пример элементарного события: "выпадение тройки при бросании кости". Пример элемента вероятностного  пространства, не являющегося элементарным: "выпадение любого чётного числа кроме двойки". Итак, свойства вероятности:

<blockquote>1. Вероятность невозможного события равна нулю.
1'. Дополнительное свойство: вероятность для всего вероятностного пространства  равна единице. 
2. Если одно событие влечёт за собой другое, то вероятность второго не превышает вероятности первого. Отношение "влечёт за собой" для событий эквивалентно "является подмножеством" для множеств. 
3. Вероятность наступления хотя бы одного из двух произвольных событий равна сумме вероятностей каждого их этих событий, минус вероятность того, что события случатся одновременно.
4. Вероятность ненаступления события равна один минус вероятность наступления события.</blockquote>
Присмотритесь к свойствам мер и вероятностей и станет видно, что мы говорим об одних и тех же свойствах.

Не все свойства вероятности вытекают из её определения, как меры: понятия независимости событий и способ вычисления вероятности одновременно двух или нескольких независимых событий как произведения из вероятностей вводятся через <i>условную вероятность</i>. Но колмогоровский подход предлагает очень ценный взгляд на это понятие.

Дискретным случайным величинам соответствуют конечные счётные множества, в них естественной мерой является обыкновенный подсчёт количества элементов. Соответственно, вероятностью в дискретном вероятностном пространстве -- комбинаторный подсчёт вариантов, знакомый каждому студенту. Для непрерывных случайных величин, вероятность, как мера, больше похожа на длину или на площадь и тут мы говорим о <i>плотностях вероятности</i>. 

Аналогия вероятности с мерой на этом не заканчиваются. Что такое <i>среднее значение</i>? Это аналог <i>положения центра масс</i> фигуры, состоящей из точечных масс или сплошного тела с известной плотностью. И вычисляются эти величины одинаково. А как характеризуется разброс случайных величин вокруг среднего: <i>дисперсия</i>? Также как <i>момент инерции</i> характеризует распределение массы вокруг центра масс. И опять, формулы вычисления дисперсии для выборки или распределения совпадают с формулами для момента инерции набора тел или твёрдого тела хитрой формы. 

Кстати, если заменить в определениях и свойствах вероятности "сумму" на "максимум", а произведение на "минимум", то можно построить альтернативную теорию, она называется <i>теорией возможностей</i>. Так работает математика. Начинаем с абстрактных рассуждений: числа образуют алгебру с операциями сложения и умножения, но на ограниченном числовом интервале можно построить подобную алгебру с операциями минимум и максимум. Строим понятие меры на новой алгебре и выясняем, что она открывает новый взгляд на мир! В отличие от теории вероятностей в такой теории можно построить две согласованные меры -- <i>возможность</i> и <i>необходимость</i>, причём они, в отличие от вероятности, хорошо согласуются как с операциями объединения, так и пересечения событий. Это направление созданное американцем Лотфи Заде, азербайджанцем по происхождению, служит основанием для <i>нечёткой логики</i> и используется в системах автоматического распознавания образов и принятия решений.

<h3>Невероятно, но факт!</h3>
Первое свойство мер кажется тривиальным, но оно интересно своей несимметричностью. Если мера подмножества равна нулю, это не значит, что оно пусто! Например, линия -- это подмножество точек плоскости, но её площадь (мера) равна нулю. Бывают и более экзотичные примеры -- канторовы и фрактальные множества, имеющие сложную структуру, содержащие бесконечное число точек, зримо "занимающие" некоторую площадь или объём, но тем не менее, имеющие нулевую меру.
<img src="https://habrastorage.org/webt/av/rx/oo/avrxoo3lawc2gyhxme6ghun8ipw.png" /><i>Некоторые объекты нулевой меры: линия на плоскости, спорадическое множество Жулиа, фрактальная губка Менгера.</i>

Готовя эту иллюстрацию, я отыскал замечательное изображения несвязного множества Жулиа на прозрачном фоне с высоким разрешением. Вставив его в векторный редактор, я столкнулся с забавной трудностью -- было очень нелегко попасть мышкой в это изображение, чтобы выделить его. Оно такое "рыхлое", что вероятность попадания в закрашенный пиксел была заметно меньше попадания в прозрачный фон. В вероятностном пространстве тоже могут существовать подмножества нулевой меры, но это не значит события из этих подмножеств невозможны. С четвёртой-пятой попытки я всё же мог выделить изображение, поскольку пиксели имеют конечный размер. Но что было бы, попади в моё распоряжение настоящее несвязное множество Жулиа с бесконечным разрешением?

Представьте себе, что вы пользуетесь программным генератором случайных чисел, который выдаёт произвольное число от $inline$0$inline$ до $inline$1$inline$. Какова вероятность выпадения числа $inline$0$inline$? а числа $inline$1/2$inline$ или $inline$e/\pi$inline$? Во всех этих случаях ответ будет -- ноль! Вернее, самое маленькое доступное компьютеру положительное число, так называемый машинный эпсилон, ведь компьютер оперирует конечным числом знаков после запятой. Подождите, скажете вы, в каком смысле -- ноль? Эти же числа не являются невозможными. Давайте проведём эксперимент, в результате мы получим какое-то конкретное число и когда мы его получим, то "по построению" вероятность его появления не может быть нулевой. Всё верно, но сколько нужно ждать до тех пор, пока не выпадет ровно 0? Практически бесконечно! Дело в том, что отдельное число, как точка на отрезке, имеет нулевую меру и честную нулевую вероятность. Отлична от нуля лишь мера отрезка, пусть даже очень маленького. Так что мы говорим не о вероятности, а о плотности вероятности, которая при умножении на конечную меру подмножества в вероятностном пространстве, даст конечную величину -- вероятность попасть в это подмножество. 

Так что если кто-то терпеливо проведёт иысячу экспериментов с монеткой и радостно скажет вам, что у него получилось столько же выпадений "орлов", сколько и "решек", можете смело выразить сомнение, либо поздравить его с редкой удачей. Хоть бросание монетки и дискретный случайный процесс, но по мере накопления статистики мощность вероятностного пространства будет расти и мера события: "число "орлов" совпадает с числом "решек"" будет уменьшаться. Можно показать, воспользовавшись формулой Стирлинга, что вероятность этого "самого вероятного" события стремится с ростом числа испытаний $inline$n$inline$ к $inline$1/\sqrt{\pi n}$inline$. Для сотни бросаний это чуть больше пяти процентов, для десяти тысяч -- всего полпроцента. В таких случаях математики говорят: <i>почти наверняка количество "орлов" не будет равно количеству "решек"</i>. Как бы странно он не звучал, но "почти наверняка" -- это точный математический термин, означающий что событие является дополнением подмножества вероятностного пространства нулевой меры. Мы ещё вернёмся к этим рассуждениям, в одной из следующих глав, когда зададимся вопросом: насколько каждый из нас может считать себя нормальным.

<h3>Проверяем честность реальной монеты</h3>

Вернёмся к монетке и к её честности. Колмогоровское определение вероятности примирило её частотное определение (как относительной частоты случающихся событий) и геометрическое (как доли "объёма" события в общем "объёме" возможностей). Таким образом, доля площади белых полосок на диаграмме рассчитанной для вращающейся монетки отражает вероятность выпадения той же стороны, которой мы её подкинули.

Но вот беда! Площадь каждой полоски на нашей диаграмме бесконечна (если рассматривать всю четверть координатной плоскости). Однако, аддитивность меры позволит нам аккуратно показать, что это не мешает площадям заштрихованных и белых областей быть одинаковыми. В явном виде уравнения для наших кривых имеют вид $inline$\omega = n/t$inline$. Если  площадь под кривой $inline$\omega = 1/t$inline$ равна $inline$S$inline$, то благодаря свойству аддитивности, площадь под кривой $inline$\omega = n/t$inline$ будет равна $inline$S_n = n S$inline$. В свою очередь, для отдельных полосок получаем: $inline$ S_{n} - S_{n-1} = n S - (n-1)S = S$inline$. Выходит, разница площадей не зависит от "номера" гиперболы. Это не что-то особенное, относящееся к гиперболам, тот же вывод можно сделать для любой кривой вида $inline$y = n f(x)$inline$, лишь бы функция $inline$f$inline$ была измерима.  А раз так, то для всей области определения, попадания в белую часть диаграммы или в заштрихованную равновероятны, как и ожидается для "честной" монетки. 

Рассуждения, которые мы сейчас привели, кажутся достаточно простыми, но они дают весьма общий результат, применимый к любым аддитивным величинам. Абстрактное понятие меры позволило нам  сравнивать между собой бесконечные величины, оставаясь в рамках логики и здравого смысла. 

Абстракции это хорошо, но можно возразить, что в реальности мы подбрасываем монетки не со всеми возможными параметрами. Как показали эксперименты со скоростной камерой, угловые скорости попадают в диапазон от $inline$20$inline$ до $inline$40$inline$ оборотов в секунду, а длительность полёта -- от половины до одной секунды. Эта область выделена прямоугольником на диаграмме. В ней суммарная площадь белых полосок чуть больше чем оранжевых, и можно сделать вывод, что вероятность выпадения той же стороны, что была при подбрасывании, составит $inline$50.6\%$inline$.

В 2007 году группа Перси Диакониса с соавторами из Стэнфорда опубликовала <a href="https://statweb.stanford.edu/~susan/papers/headswithJ.pdf">статью</a>, в которой даётся развёрнутый анализ  процесса подбрасывания монетки. Детальное описание механики летящего и вращающегося диска, который, не просто вращается вокруг какой-то оси, а ещё и прецессирует -- ось вращения сама вращается в полёте, показывает, что при ручном подбрасывании из позиции орел сверху, вероятность выпадения орла на одну сотую больше половины. 

Много это или мало? Сколько нужно провести экспериментов, чтобы заметить такую разницу? По мере накопления экспериментальных данных, стандартная ошибка среднего, отражающая погрешность, с которой может быть вычислена средняя величина, уменьшается пропорционально квадратному корню из числа испытаний: $inline$\sigma_{\mu} = \sigma/\sqrt{n}$inline$, здесь $inline$\sigma$inline$ -- стандартное отклонение для исследуемого распределения. В нашем случае, для распределения Бернулли с вероятностью $inline$0.51$inline$, которое равно $inline$\sqrt{0.51\times0,49}\approx0.5$inline$. Чтобы уверенно выделить отклонение среднего в одну сотую, это отклонение должно превышать $inline$3$inline$ стандартных отклонения. Таким образом, мы можем оценить число испытаний: $$display$$n =
\left(\frac{\sigma}{\sigma_{\mu}}\right)^2 = \left(\frac{3\times0.5}{0.01}\right)^2 \approx 22500$$display$$ Столько раз нужно подбросить монетку, чтобы заметить механистическую предопределённость результата. Чтобы было понятнее, что имеется ввиду, приведу пример двухсот испытаний идеальной и слегка неидеальной "монеток", проводимых с целью вычислить вероятность выпадения, скажем, орла. Каждое испытание состоит в $inline$40000$inline$ "подбрасываниях". Слова "монетка" и "подбрасывание" взяты в кавычки, оттого, что на самом деле использовалась не физическая монетка, а генератор случайных чисел, подчиняющихся распределению Бернулли.

<img src="https://habrastorage.org/webt/pq/d2/hp/pqd2hpbqdysnxmwcw19gcili-kc.png" width="80%" align="center"/><i><font color="#444">Эксперименты с подбрасыванием идеальной и слегка неидеальной монетки с целью зафиксировать неидеальность.</font></i>

Видно, что только после $inline$20000$inline$ испытаний "облака" наблюдаемых значений среднего начинают отчётливо разделяться. Что же, для бытового использования можно считать, что монетка -- неплохой генератор случайного выбора из двух равновероятных вариантов. 

<h3>Закон туриста </h3>
Эквивалентность геометрического и частотного определения вероятности раскрывает загадку одного закона подлости, известного в кругу туристов, геологов и всех тех, что пользуется топографическими картами:
<blockquote>То место, куда направляется турист, чаще всего оказывается либо на сгибе карты, либо на краю листа.</blockquote>
Предположим, что нас одинаково часто интересуют объекты, расположенные во всех участках карты. Но нас редко интересуют объекты нулевой меры -- весь смысл использования карты состоит в обозрении <i>окрестностей </i>объекта, то есть некоторой конечной площади. Пусть нам достаточно будет некоторой малой доли $inline$\alpha$inline$ от площади всей карты $inline$S$inline$, чтобы разобраться в том, как попасть к объекту. Значит, если объект приблизится к сгибу или краю на какое-то критическое расстояние $inline$d$inline$, мы сочтём закон туриста выполнившимся. Доля пограничных площадей в общем площади карты даст нам вероятность испытать этот закон подлости на себе. Вот как выглядят неприятные участки карты при $inline$\alpha=0.5%$inline$ и одном сгибе.

<img src="https://habrastorage.org/webt/sa/ix/tu/saixtuhiooqe8he3spet60dp5ps.png" width="70%" align="center"/><i><font color="#444">Серым выделены "нехорошие" участки. Отдельно показан участок с полупроцентной площадью для карты шириной в 40 см, имеет диаметр слегка превышающий 3 см.</font></i>

Для квадратной карты $inline$d = \sqrt{\alpha S}$inline$. Неприятные полоски будут иметь площадь $inline$d \sqrt{S} = S\sqrt{\alpha}$inline$. Четыре полосы, две вертикальные и две горизонтальные, расположатся у края, любой дополнительный изгиб, горизонтальный или вертикальный, добавит ещё одну полоску. При этом пересекающиеся полоски добавляют лишние квадратики площадью $inline$d^2 = \alpha S$inline$. Сложив карту так, чтобы получилось $inline$n$inline$ горизонтальных и $inline$m$inline$ вертикальных изгибов, мы получим суммарную площадь неприятной зоны равную: $inline$S(n+2)\sqrt{\alpha}+S(m+2)\sqrt{\alpha}-S(n+2)(m+2)\alpha$inline$. Отнеся её к площади всей карты, получим неприятную долю общей площади: 
$$display$$p = (n+m + 4)\sqrt{\alpha} - (n+2)(m+2)\alpha.$$display$$
На рисунке показаны области, в которых эта доля превышает $inline$50\%$inline$ для различных значений $inline$\alpha$inline$.

<img src="https://habrastorage.org/webt/9m/tg/_a/9mtg_arh5sm4l_gg1lxl2kbpqqy.png" width="70%" align="center"/><i><font color="#444">Области, в которых повышена вероятность оказаться на сгибе карты или на её краю. Числами отмечена доля площади рассматриваемой окрестности от площади всей карты.</font></i>

Получается, что карта, сложенная пополам дважды уже может формально  считаться нечестной по отношению к туристу. Чаще всего, карты имеют по три вертикальные и три горизонтальные складки, что даёт вероятность выполнения закона подлости с вероятностью $inline$58\%$inline$.

<h3>Источники случайности</h3>

<img src="https://habrastorage.org/webt/9i/tt/42/9itt42myvc71zegikqmk7mro9jy.jpeg" width="35%" align="left"/>В сувенирных лавках можно найти магнитные маятники для "выбора желаний". Они тоже являются механическими генераторами случайности и их иногда ошибочно называют "хаотическими маятниками". Начав движение с каких-то начальных позиции и скорости, маятник совершает ряд "непредсказуемых" колебаний и, наконец, останавливается в одном из секторов. Однако колебания и здесь не являются непредсказуемыми, просто они очень чувствительны к начальным условиям. Для каждого сектора, в котором может остановиться маятник, существует <i>область притяжения</i> в пространстве координат-скорости. Это множество таких начальных условий при которых маятник обязательно притянется к определённой точке в указанном секторе. Точка в которой заканчивается движение маятника называется <i>аттрактором</i> -- притягивающей точкой. В случае маятника с картинки пространство координат и скоростей четырёхмерно, и так просто области притяжения не показать. Но если ограничиться лишь двумя секторами и свести задачу к одномерной (такой маятник называется осциллятором Дюффинга), то пространство начальных значений превратится в плоскость, так что области притяжения можно будет увидеть. Они выглядят как замысловатый символ "Инь-Янь", быстро превращающийся в узкие полоски, разделяющие области притяжения. 

<img src="https://habrastorage.org/webt/yq/lc/dy/yqlcdyo5rpkf-ewr7nbo4cxengo.png" width="70%" align="center"/><i><font color="#444">Области притяжения аттракторов для одномерного маятника желаний -- осциллятора Дюффинга.</font></i>

Как и в случае с монетой, немного смещая начальные условия мы попадаем от одного аттрактора к другому. Так же действует и игральная кость и рулетка, но они не являются сами по себе генераторами случайности. Это не истинно хаотические системы и их поведение можно точно рассчитать. 

А что же такое настоящая случайность? Хороший пример истинно стохастической системы -- появление автомобилей на дороге. Люди не договариваются, не согласовывают свои планы, каждый элемент ансамбля за пределами дороги действует независимо. И хотя в поведении людей есть определённые закономерности -- часы пик утром и вечером, пустые дороги ночью и т.д., мы не обладаем и никогда не будем обладать достаточной информацией о каждом участнике движения, чтобы предсказать появление любого из них. Также стохастическими являются механика элементарных частиц на квантовом уровне, распад нестабильных атомов, изменения в генетическом коде, по всей видимости, землетрясения и котировки ценных бумаг на бирже. Единственное, что остаётся исследователю, это рассматривать их, как случайные величины и описывать в терминах теории вероятности.

Но есть и другой источник случайностей -- <i>динамический хаос</i>. Хаотические системы отличаются от стохастических тем, что описываются точными уравнениями и параметрами, не содержащими случайностей. Однако их поведение не просто сложно, а хаотично и истинно непредсказуемо. Если мы начнём колебать маятник желаний, очень аккуратно, с точно контролируемой частотой и амплитудой, то мы обнаружим что его плавные движения невозможно просчитать надолго. Никакими алгоритмами на сколь угодно точных вычислительных машинах нам не удастся рассчитать точное поведение маятника на произвольно долгое будущее. Он не остановится на каком-либо секторе, а будет совершать плавные движения, но никогда не вернётся в одну и ту же точку в пространстве координат-скорости дважды. Ещё один пример предельно простой хаотической системы -- идеальный шарик, подпрыгивающий в поле тяжести на идеальном столике с пружинкой. Сравнительно простые уравнения Лоренца показали, что мы никогда не сможем предсказывать погоду больше чем на пару-тройку недель -- это тоже хаотическая система. 

Теории динамического хаоса, удалось объяснить природу такой непредсказуемости. Простой одномерный маятник желаний, который мы рассматривали, имел две устойчивые стационарные точки -- два аттрактора, и одну неустойчивую, от  которой система старается уйти, она показана белым кружком. В хаотическом режиме вместо набора аттракторов в системе появляется бесконечное множество неустойчивых стационарных траекторий. Это множество бесконечно, но имеет <i>нулевую меру</i>, и представляет собой очень сложно устроенную несвязную структуру. Попав на одну таких траекторий, в принципе невозможно ей следовать, используя какие-либо конечные алгоритмы. Но самое удивительное, оказалось, что это бесконечное множество неустойчивых траекторий само по себе является притягивающим! <img src="https://habrastorage.org/webt/z-/m3/do/z-m3do2rhl7w0uzt4idcnepnpxa.png" width="50%" align="right"/> Хаотическая система непрерывно перескакивает от окрестности одной неустойчивой траектории к другой, всё время оставаясь в пределах это странного аттрактора. Так эти множества и называются: <i>странные аттракторы</i>. Вот как завораживающе красиво выглядит сечение плоскостью странного аттрактора для маятника желаний, подверженного гармоническим колебаниям. Этот объект для одномерного маятника можно описать в трёхмерном пространстве (координата, скорость, фаза вынужденного колебания). Если рассечь аттрактор в этом пространстве плоскостью то можно увидеть его структуру, это называется <i>сечением Пуанкаре</i>. Каждая точка здесь -- это след траектории, а цвет точек отражает относительную скорость с которой траектории разбегаются друг от друга. Вот ещё пара красивых странных аттракторов:
<img src="https://habrastorage.org/webt/x7/x2/vl/x7x2vlyryztmd01vjzuoekqyjg0.png" width="60%" /><img src="https://habrastorage.org/webt/yf/if/ve/yfifvev6krrghkxje8l4chntal0.jpeg" width="40%" />
<i><font color="#444">Слева: сечение Пуанкаре для траектории шарика, подпрыгивающего на подпружиненном столике. Множество точек принадлежит поверхности сферы, соответствующей закону сохранения энергии. Справа: объемная область, которая заключает в себе странный аттрактор, рождающийся при вынужденных колебаниях толстой пластины.</font></i>

Гладкость хаотической траектории позволяет всё же немного заглядывать в будущее. Это объясняет одно досадное наблюдение: с одной стороны, синоптики, порой, не могут уверенно предсказать погоду на неделю, но с другой, если вы скажете, что завтра будет такая же погода, как и сегодня, то не ошибётесь примерно в трёх случаях из четырёх. Вообще же, анекдоты о синоптиках несправедливы и нужно отдать должное человеческой мысли и упорству, которые позволили предсказывать погоду на современном уровне! 



Динамический хаос очень сложен и красив как теория, он порождает изумительные по элегантности образы, но он может быть ещё и полезен. Например, алгоритмы, с помощью которых генерируются случайные числа в компьютерах тоже детерминированы. Для примеров в этой книге, я пользовался генератором псевдослучайных чисел, который не запускал реальный стохастический процесс (альфа-распад, или подсчёт машин на дороге), а вычислял следующее "случайное" число на базе предыдущих, полученных им ранее.

<h3>От монеток к бабочкам и самой судьбе</h3>

Наблюдения за тем, как малые отклонения вырастают в глобальные изменения системы, приводят к мысли об "эффекте бабочки". Напомню, что под этим эффектом подразумевается цепочка далеко идущих драматичных последствий от некоторого незначительного, на первый взгляд, события. Раздавленная исследователями прошлого бабочка в рассказе Рея Бредбери "И грянул гром" привела к кардинальной перестройке будущего. А одну из своих лекций Эдвард Лоренц, создатель теории динамического хаоса, озаглавил так: "Может ли взмах крыла бабочки в Бразилии вызвать торнадо в Техасе?"

На этот эффект мы неявно ссылаемся, сетуя: "Не поверни я за угол, всё было бы по-другому!", "Не сел бы он в этот поезд, с ним не случилось бы катастрофы!" или "Из-за такой мелочи разругались и разошлись!!" Но мы видим, что в мире сосуществуют истинно стохастический квантовый мир и сверхточные атомные часы, устойчивые гамильтоновы системы в мире звёзд и галактик и хаос колец Сатурна и пояса Койпера, тепловое движения молекул и удивительная точность работы биологических систем или механизмов автомобиля. Нет, взмах крыла бабочки не порождает ураганов, а бесследно исчезает, порождая цепочку вихрей, передающих энергию и информацию всё более и более мелким вихрям, покуда и та и другая не исчезнут в хаосе флуктуаций.  Надо чётко понимать, что малые отклонения приводят к кардинальной перестройке системы лишь, если она неустойчива или если система находится на пороге <i>бифуркации</i> или <i>катастрофы</i> -- так на языке математики называются глобальные перестройки в поведении системы при малых изменениях параметров. А бифуркации всегда образуют множества нулевой меры в пространстве параметров -- это точки или границы. Малые возмущения не приводят к катастрофам <i>почти всюду</i>, (это точный термин означающий "везде, кроме множества нулевой меры"), а неустойчивые состояния в природе наблюдаются редко, не проходя "проверку временем".  

Если пара распалась "из-за ерунды", ей суждено было распасться в любом случае, она была неустойчивой. Устойчивые пары проходят сквозь войны и голод, а потом, бывает и, распадаются, но не из-за мелочей, а в результате глубоких перемен, могущих произойти с личностью в течение жизни. В цепочке событий, приведших к катастрофе поезда нелегко однозначно выделить ключевое событие (конкретную ошибку или роковую случайность) и, скорее всего, ключевым будет не событие, а систематическое нарушение правил, приводящее систему к неустойчивому состоянию.  Если в системе множество параметров, и ряд из них случаен, а наша жизнь устроена именно так, то информация в такой системе имеет свойство теряться и уже никак не удастся восстановить в какой именно момент в нашей жизни "всё пошло не так". Не терзайте себя сожалениями о случившемся, а присмотритесь к происходящему с вами сейчас, чтобы не пропустить настоящей точки бифуркации.

В этой связи можно вспомнить один из законов мерфологии, названный неким Дрейзеном <b>законом восстановления</b>:
<blockquote>Время улучшения ситуации обратно пропорционально времени ее ухудшения.
</blockquote>В качестве примера приводится следующее наблюдение: <i><font color="#800">На склеивание вазы уходит больше времени, чем на то, чтобы ее разбить.</font></i> Этот закон удивительно точно описывает соотношение между характерными временами для процесса <i>релаксации</i> для устойчивой системы, которую можно описать убывающим экспоненциальным законом и времени развития <i>катастрофического</i> процесса в неустойчивой системе, в линейном приближении -- экспоненциальным ростом малого возмущения. Пример с вазой, правда относится к другому процессу -- к <i>самоорганизации</i>, этот процесс в первом приближении описывается <i>логистическим</i> законом и близок по характеру к релаксации.

<img src="https://habrastorage.org/webt/xz/_f/r1/xz_fr1uqxevsvvaq9orghxxbqda.png" width="70%" align="center"/><i><font color="#444">Типичные нестационарные процессы: катастрофа, релаксация и самоорганизация, имеющие одинаковое характерное время.</font></i>

$$display$$* * *$$display$$

Иногда, гуляя в снегопад, я удивляюсь тому, что снежинка падает мне на нос. Удивляюсь оттого, что вероятность этого события была ничтожно мала. Если рассудить, она родилась высоко в небе над Тихим океаном, кружилась в беспорядочных турбулентных потоках в облаке, падала непрерывно меняя направление движения.. чтобы попасть на кончик моего носа! А какой ошеломительный путь прошли фотоны от далёкой звезды!? Десятки тысяч лет они неслись сквозь Вселенную, их не поглотила пыль им не встретился астероид! Родились они в квантовом мире далёкой звезды, а закончили свой путь в квантовом мире белка опсина на сетчатке в моём глазу. Даже считать вероятность этого события нет смысла, она равно нулю, но событие случается, и я вижу мерцающий свет звезды. Теперь понятно, что это всё потому, что площадь моего носа и даже молекулы имеют ненулевую меру, но всё равно удивительно: то, что почти наверняка не должно было произойти, всё же происходит!

О предопределённости или случайности судьбы, об истинности или призрачности нашего знания о природе  пусть спорят философы. Я призываю читателя взглянуть на мир с высоты математических абстракций и восхититься его красотой и согласованностью.
